{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from math import pi\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from xgboost import XGBRegressor\n",
    "import holidays\n",
    "from datetime import timedelta\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv('./actuals.csv')\n",
    "\n",
    "train_cut = int(len(data) * 0.8)\n",
    "validate_cut = int(len(data) * 0.9)\n",
    "\n",
    "train, validate, test = data.iloc[0:train_cut], data.iloc[train_cut-7*24:validate_cut], data.iloc[validate_cut-7*24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>icon</th>\n",
       "      <th>precip_prob</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>77.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>75.62</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.93</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.31</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.16</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-06-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>72.42</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  sunrise   icon  precip_prob  temperature  humidity  \\\n",
       "0  2013-06-01 00:00:00        0  clear         0.01        77.65      0.61   \n",
       "1  2013-06-01 01:00:00        0  clear         0.01        75.62      0.67   \n",
       "2  2013-06-01 02:00:00        0  clear         0.01        74.72      0.70   \n",
       "3  2013-06-01 03:00:00        0  clear         0.01        73.32      0.76   \n",
       "4  2013-06-01 04:00:00        0  clear         0.01        72.42      0.79   \n",
       "\n",
       "   wind_speed  rides  \n",
       "0        2.06    152  \n",
       "1        1.93    102  \n",
       "2        2.31     67  \n",
       "3        2.16     41  \n",
       "4        1.93     16  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train, train['rides']\n",
    "X_validate, y_validate = validate, validate['rides']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dummy Predictor</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is helpful to start with a heuristic predictor. The type of predictor that can be used without any statistical or machine learning knowledge. We can compare our ML work against this predictor to determine what type of improvement machine learning has added. \n",
    "\n",
    "In this heuristic I am simply making predictions by going back in time 1 year and finding the closest day of the week and resuing that number. That is, I am using the 3rd Wednesday in June 2015 to predict the 3rd Wednesday in June 2016. In the event that that information is not available, I simply take the last available data from the same hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearAgoRegressor(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.X = X.loc[:, ['date', 'hour']]\n",
    "        self.X['date'] = self.X['date'].map(lambda x: pd.to_datetime(x))\n",
    "        self.X['rides'] = y\n",
    "        return self\n",
    "    \n",
    "    def _meaning(self, x):\n",
    "        prev_year = pd.to_datetime(x.date) - pd.DateOffset(years=1)\n",
    "        day_delta = int(prev_year.strftime('%w')) + 1 - x.day_of_week\n",
    "        prev_year = prev_year - pd.Timedelta(days=day_delta)\n",
    "        if not self.X[(self.X.date == prev_year) & (self.X.hour == x.hour)].empty:\n",
    "            return self.X[(self.X.date == prev_year) & (self.X.hour == x.hour)].iloc[0, :].rides\n",
    "        return self.X[(self.X.hour == x.hour)].iloc[-1, :].rides\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        return(X.apply(self._meaning, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=3),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None, steps=[('yearagoregressor', YearAgoRegressor())]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "pipeline = make_pipeline(\n",
    "    YearAgoRegressor()\n",
    ")\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(3), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(train, train.rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-843615.1207858355"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MSE of ~843615 will serve as my baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.columns]\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.func(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['sunrise'])),\n",
    "            ('cat_ohe', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', CustomTransformer(lambda y: y.applymap(lambda x: float(pd.to_datetime(x).year - 2013)))),\n",
    "            ('year_scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed', 'lag7', 'lag1'])),\n",
    "            ('int_scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('rad', Pipeline([\n",
    "            ('rad_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('rad_cos_sin', FeatureUnion([\n",
    "                ('rad_cos', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.cos(x * pi * 2/ x.nunique()), 5)))),\n",
    "                ('rad_sin', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.sin(x * pi * 2/ x.nunique()), 5))))\n",
    "            ]))  \n",
    "        ]))\n",
    "    ])),\n",
    "    ('svr', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.2min finished\n",
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=3),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('cat', Pipeline(memory=None,\n",
       "     steps=[('cat_selector', ColumnSelector(columns=['sunrise'])), ('cat_ohe', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "   ...\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'svr__C': [500], 'svr__gamma': [0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'svr__C': [500],\n",
    "          'svr__gamma': [0.1]}\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(3), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-399577.7994155443"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['sunrise'])),\n",
    "            ('cat_ohe', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', CustomTransformer(lambda y: y.applymap(lambda x: float(pd.to_datetime(x).year))))\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed', 'lag7', 'lag1']))\n",
    "        ])),\n",
    "        ('rad', Pipeline([\n",
    "            ('rad_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('rad_cos_sin', FeatureUnion([\n",
    "                ('rad_cos', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.cos(x * pi * 2/ x.nunique()), 5)))),\n",
    "                ('rad_sin', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.sin(x * pi * 2/ x.nunique()), 5))))\n",
    "            ]))  \n",
    "        ]))\n",
    "    ])),\n",
    "#     ('rfr', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   13.9s remaining:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   38.2s finished\n",
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('cat', Pipeline(memory=None,\n",
       "     steps=[('cat_selector', ColumnSelector(columns=['sunrise'])), ('cat_ohe', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "   ...s='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'rfr__n_estimators': [500], 'rfr__max_depth': [20], 'rfr__max_features': ['sqrt']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'rfr__n_estimators': [500],\n",
    "          'rfr__max_depth': [20],\n",
    "          'rfr__max_features': ['sqrt'],\n",
    "         }\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(5), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-369508.5522853572"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lag7', 0.3463949735035121)\n",
      "('lag1', 0.17154210262273634)\n",
      "('day_of_week', 0.06590111463786616)\n",
      "('sunrise', 0.06363612025506829)\n",
      "('hour', 0.062128882638282645)\n",
      "('temp', 0.06184890902621661)\n",
      "('sunrise', 0.0584629724357565)\n",
      "('precip', 0.033230805218876835)\n",
      "('humidity', 0.031512837101652216)\n",
      "('date', 0.024000556872802285)\n",
      "('month', 0.0191005571724678)\n",
      "('hour', 0.018753165317310465)\n",
      "('month', 0.017347952947530405)\n",
      "('wind_speed', 0.015106824140427468)\n",
      "('day_of_week', 0.011032226109493358)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(zip(['sunrise', 'sunrise', 'date', 'precip', 'temp',\n",
    "             'humidity', 'wind_speed', 'lag7', 'lag1', 'hour', 'hour', 'day_of_week', 'day_of_week', 'month', 'month']\n",
    "             , clf.best_estimator_.named_steps['rfr'].feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>XG Boost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HolidaySelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        hd = [date for date, name in holidays.US(years=[2013, 2014, 2015, 2016, 2017, 2018]).items()\n",
    "                        if name.startswith((\"New Year's Day\", \"Washington's Birthday\", \"Memorial Day\", \"Independence Date\",\n",
    "                        \"Labor Day\", \"Thanksgiving\", \"Christmas Day\"))]\n",
    "        hd_eve = [day - timedelta(days=1) for day in hd]\n",
    "        hd.extend(hd_eve)\n",
    "        self.h = [str(date) for date in hd]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[['date']].applymap(lambda x: int(pd.to_datetime(x).strftime('%Y-%m-%d') in self.h))\n",
    "    \n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.columns]\n",
    "    \n",
    "\n",
    "class DateTimeExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, extract):\n",
    "        self.extract = extract\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X[['date']].applymap(lambda x: float(getattr(pd.to_datetime(x), self.extract)))\n",
    "\n",
    "\n",
    "class LagTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, amount):\n",
    "        self.amount=amount\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[['rides']].shift(self.amount, fill_value=0)\n",
    "\n",
    "class CosExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.unique = X.nunique()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(lambda x: np.round(np.cos(x * pi * 2/ self.unique), 5), axis=1)\n",
    "\n",
    "class SinExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.unique = X.nunique()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(lambda x: np.round(np.sin(x * pi * 2/ self.unique), 5), axis=1)\n",
    "\n",
    "        \n",
    "pipeline = Pipeline([\n",
    "            ('union', FeatureUnion([\n",
    "                ('holiday', HolidaySelector()),\n",
    "                ('year_extractor', DateTimeExtractor('year')),\n",
    "                ('weather_selector', ColumnSelector(['sunrise', 'precip_prob', 'temperature', 'humidity', 'wind_speed'])),\n",
    "                ('lag7', LagTransformer(7*24)),\n",
    "                ('lag2', LagTransformer(2*24)),\n",
    "                ('hour_pipeline', Pipeline([\n",
    "                    ('hour', DateTimeExtractor('hour')), \n",
    "                    ('hour_union', FeatureUnion([\n",
    "                        ('hour_cos', CosExtractor()),\n",
    "                        ('sin_cos', SinExtractor())\n",
    "                    ]))\n",
    "                ])),\n",
    "                ('month_pipeline', Pipeline([\n",
    "                    ('month', DateTimeExtractor('month')), \n",
    "                    ('month_union', FeatureUnion([\n",
    "                        ('month_cos', CosExtractor()),\n",
    "                        ('month_sin', SinExtractor())\n",
    "                    ]))\n",
    "                ])),\n",
    "                ('dayofweek_pipeline', Pipeline([\n",
    "                    ('dayofweek', DateTimeExtractor('dayofweek')), \n",
    "                    ('dayofweek_union', FeatureUnion([\n",
    "                        ('dayofweek_cos', CosExtractor()),\n",
    "                        ('dayofweek_sin', SinExtractor())\n",
    "                    ]))\n",
    "                ])),\n",
    "            ])),\n",
    "            ('xgbregressor', XGBRegressor())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.3min remaining:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('holiday', HolidaySelector()), ('year_extractor', DateTimeExtractor(extract='year')), ('weather_selector', ColumnSelector(columns=['sunrise', 'precip_prob', 'temperature', 'humidity', 'wind_speed'])), ('lag7', LagTransformer(amount...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'xgbregressor__eta': [0.005], 'xgbregressor__max_depth': [5], 'xgbregressor__n_estimators': [900], 'xgbregressor__colsample_bytree': [0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'xgbregressor__eta': [.005],\n",
    "          'xgbregressor__max_depth': [5],\n",
    "          'xgbregressor__n_estimators': [900],\n",
    "          'xgbregressor__colsample_bytree': [0.5],\n",
    "         }\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(5), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-265509.24243202107"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xg.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(clf.best_estimator_, 'xg.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lag7', 0.13809206)\n",
      "('temperature', 0.13279441)\n",
      "('lag2', 0.12423969)\n",
      "('wind_speed', 0.09159047)\n",
      "('humidity', 0.08362438)\n",
      "('hour_cos', 0.06094259)\n",
      "('hour_sin', 0.06011851)\n",
      "('precip', 0.058470353)\n",
      "('dayofweek_sin', 0.05839187)\n",
      "('year', 0.04485343)\n",
      "('month_cos', 0.04124318)\n",
      "('dayofweek_cos', 0.03669113)\n",
      "('month_sin', 0.035749324)\n",
      "('sunrise', 0.019228505)\n",
      "('holiday', 0.0139700975)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(zip(['holiday', 'year', 'sunrise', 'precip', 'temperature', 'humidity', 'wind_speed', \n",
    "                     'lag7', 'lag2', 'hour_cos', 'hour_sin', 'month_cos', 'month_sin', 'dayofweek_cos', 'dayofweek_sin']\n",
    "             , clf.best_estimator_.named_steps['xgbregressor'].feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
