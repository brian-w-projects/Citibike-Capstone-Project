{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from math import pi\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./historic_data.csv')\n",
    "data['lag7'] = data['rides'].shift(7*24)\n",
    "data['lag1'] = data['rides'].shift(1*24)\n",
    "data.drop(['icon'], axis=1, inplace=True)\n",
    "\n",
    "train_cut = int(len(data) * 0.8)\n",
    "validate_cut = int(len(data) * 0.9)\n",
    "\n",
    "train, validate, test = data.iloc[7*24:train_cut, :], data.iloc[train_cut:validate_cut, :], data.iloc[validate_cut:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>precip_prob</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>60.44</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.84</td>\n",
       "      <td>152.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>59.48</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.88</td>\n",
       "      <td>102.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>58.81</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.17</td>\n",
       "      <td>67.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>58.25</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.17</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>57.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6.30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  hour  month  day_of_week  sunrise  precip_prob  temperature  \\\n",
       "168  2013-06-08     0      6            7        0         0.93        60.44   \n",
       "169  2013-06-08     1      6            7        0         0.92        59.48   \n",
       "170  2013-06-08     2      6            7        0         0.90        58.81   \n",
       "171  2013-06-08     3      6            7        0         0.94        58.25   \n",
       "172  2013-06-08     4      6            7        0         0.83        57.63   \n",
       "\n",
       "     humidity  wind_speed   lag7  lag1  \n",
       "168      0.94        5.84  152.0  51.0  \n",
       "169      0.94        4.88  102.0  36.0  \n",
       "170      0.94        5.17   67.0  16.0  \n",
       "171      0.94        5.17   41.0   8.0  \n",
       "172      0.94        6.30   16.0   4.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train.iloc[:, train.columns != 'rides'], train.iloc[:, train.columns == 'rides'].iloc[:, 0]\n",
    "X_validate, y_validate = validate.iloc[:, validate.columns != 'rides'], validate.iloc[:, validate.columns == 'rides'].iloc[:, 0]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dummy Predictor</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is helpful to start with a heuristic predictor. The type of predictor that can be used without any statistical or machine learning knowledge. We can compare our ML work against this predictor to determine what type of improvement machine learning has added. \n",
    "\n",
    "In this heuristic I am simply making predictions by going back in time 1 year and finding the closest day of the week and resuing that number. That is, I am using the 3rd Wednesday in June 2015 to predict the 3rd Wednesday in June 2016. In the event that that information is not available, I simply take the last available data from the same hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearAgoRegressor(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.X = X.loc[:, ['date', 'hour']]\n",
    "        self.X['date'] = self.X['date'].map(lambda x: pd.to_datetime(x))\n",
    "        self.X['rides'] = y\n",
    "        return self\n",
    "    \n",
    "    def _meaning(self, x):\n",
    "        prev_year = pd.to_datetime(x.date) - pd.DateOffset(years=1)\n",
    "        day_delta = int(prev_year.strftime('%w')) + 1 - x.day_of_week\n",
    "        prev_year = prev_year - pd.Timedelta(days=day_delta)\n",
    "        if not self.X[(self.X.date == prev_year) & (self.X.hour == x.hour)].empty:\n",
    "            return self.X[(self.X.date == prev_year) & (self.X.hour == x.hour)].iloc[0, :].rides\n",
    "        return self.X[(self.X.hour == x.hour)].iloc[-1, :].rides\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        return(X.apply(self._meaning, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=3),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None, steps=[('yearagoregressor', YearAgoRegressor())]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "pipeline = make_pipeline(\n",
    "    YearAgoRegressor()\n",
    ")\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(3), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(train, train.rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-777558.4309392265"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MSE of ~777558 will serve as my baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.columns]\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.func(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['sunrise'])),\n",
    "            ('cat_ohe', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', CustomTransformer(lambda y: y.applymap(lambda x: float(pd.to_datetime(x).year - 2013)))),\n",
    "            ('year_scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed', 'lag7', 'lag1'])),\n",
    "            ('int_scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('rad', Pipeline([\n",
    "            ('rad_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('rad_cos_sin', FeatureUnion([\n",
    "                ('rad_cos', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.cos(x * pi * 2/ x.nunique()), 5)))),\n",
    "                ('rad_sin', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.sin(x * pi * 2/ x.nunique()), 5))))\n",
    "            ]))  \n",
    "        ]))\n",
    "    ])),\n",
    "    ('svr', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.2min finished\n",
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=3),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('cat', Pipeline(memory=None,\n",
       "     steps=[('cat_selector', ColumnSelector(columns=['sunrise'])), ('cat_ohe', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "   ...\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'svr__C': [500], 'svr__gamma': [0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'svr__C': [500],\n",
    "          'svr__gamma': [0.1]}\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(3), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-271343.6329093849"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['sunrise'])),\n",
    "            ('cat_ohe', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', CustomTransformer(lambda y: y.applymap(lambda x: float(pd.to_datetime(x).year))))\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed', 'lag7', 'lag1']))\n",
    "        ])),\n",
    "        ('rad', Pipeline([\n",
    "            ('rad_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('rad_cos_sin', FeatureUnion([\n",
    "                ('rad_cos', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.cos(x * pi * 2/ x.nunique()), 5)))),\n",
    "                ('rad_sin', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.sin(x * pi * 2/ x.nunique()), 5))))\n",
    "            ]))  \n",
    "        ]))\n",
    "    ])),\n",
    "    ('rfr', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   15.4s remaining:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   39.9s finished\n",
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('cat', Pipeline(memory=None,\n",
       "     steps=[('cat_selector', ColumnSelector(columns=['sunrise'])), ('cat_ohe', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "   ...s='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'rfr__n_estimators': [500], 'rfr__max_depth': [20], 'rfr__max_features': ['sqrt']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'rfr__n_estimators': [500],\n",
    "          'rfr__max_depth': [20],\n",
    "          'rfr__max_features': ['sqrt'],\n",
    "         }\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(5), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-255269.71239256524"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lag7', 0.30893856577072853)\n",
      "('lag1', 0.24446463869450927)\n",
      "('sunrise', 0.06536291274141612)\n",
      "('hour', 0.062456836844871154)\n",
      "('sunrise', 0.058045963410199464)\n",
      "('day_of_week', 0.05782371546325876)\n",
      "('temp', 0.05395122559158719)\n",
      "('precip', 0.03254889439178792)\n",
      "('humidity', 0.02706546816265378)\n",
      "('date', 0.019569183415959198)\n",
      "('month', 0.01691642987612846)\n",
      "('hour', 0.016632279994740717)\n",
      "('wind_speed', 0.013133174028038867)\n",
      "('month', 0.012645460354546854)\n",
      "('day_of_week', 0.010445251259573917)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(zip(['sunrise', 'sunrise', 'date', 'precip', 'temp',\n",
    "             'humidity', 'wind_speed', 'lag7', 'lag1', 'hour', 'hour', 'day_of_week', 'day_of_week', 'month', 'month']\n",
    "             , clf.best_estimator_.named_steps['rfr'].feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>XG Boost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.applymap(lambda x: float(pd.to_datetime(x).year))\n",
    "\n",
    "class CosExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.unique = X.nunique()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(lambda x: np.round(np.cos(x * pi * 2/ self.unique), 5), axis=1)\n",
    "\n",
    "class SinExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.unique = X.nunique()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(lambda x: np.round(np.sin(x * pi * 2/ self.unique), 5), axis=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['sunrise'])),\n",
    "            ('cat_ohe', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', YearExtractor())\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed', 'lag7', 'lag1']))\n",
    "        ])),\n",
    "        ('rad', Pipeline([\n",
    "            ('rad_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('rad_cos_sin', FeatureUnion([\n",
    "                ('rad_cos', CosExtractor()),\n",
    "                ('rad_sin', SinExtractor())\n",
    "            ]))  \n",
    "        ]))\n",
    "    ])),\n",
    "    ('xg', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   50.1s remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min finished\n",
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('cat', Pipeline(memory=None,\n",
       "     steps=[('cat_selector', ColumnSelector(columns=['sunrise'])), ('cat_ohe', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "   ...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'xg__eta': [0.005], 'xg__max_depth': [5], 'xg__n_estimators': [900], 'xg__colsample_bytree': [0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'xg__eta': [.005],\n",
    "          'xg__max_depth': [5],\n",
    "          'xg__n_estimators': [900],\n",
    "          'xg__colsample_bytree': [0.5],\n",
    "         }\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(5), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-218787.14651197355"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xg.pkl']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(clf.best_estimator_, 'xg.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lag1', 0.14694831)\n",
      "('temp', 0.13877323)\n",
      "('lag7', 0.12902407)\n",
      "('wind_speed', 0.093784906)\n",
      "('humidity', 0.08474662)\n",
      "('month', 0.058951966)\n",
      "('day_of_week', 0.058342643)\n",
      "('precip', 0.0551437)\n",
      "('hour', 0.05037067)\n",
      "('hour', 0.046714734)\n",
      "('date', 0.03996141)\n",
      "('day_of_week', 0.039504416)\n",
      "('month', 0.03442673)\n",
      "('sunrise', 0.014877628)\n",
      "('sunrise', 0.008428963)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(zip(['sunrise', 'sunrise', 'date', 'precip', 'temp',\n",
    "             'humidity', 'wind_speed', 'lag1', 'lag7', 'hour', 'hour', 'day_of_week', 'day_of_week', 'month', 'month']\n",
    "             , clf.best_estimator_.named_steps['xg'].feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
