{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from math import pi\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./historic_data.csv')\n",
    "data['lag7'] = data['rides'].shift(7*24)\n",
    "data['lag1'] = data['rides'].shift(2*24)\n",
    "data.drop(['icon'], axis=1, inplace=True)\n",
    "\n",
    "train_cut = int(len(data) * 0.8)\n",
    "validate_cut = int(len(data) * 0.9)\n",
    "\n",
    "train, validate, test = data.iloc[7*24:train_cut, :], data.iloc[train_cut:validate_cut, :], data.iloc[validate_cut:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>precip_prob</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>60.44</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.84</td>\n",
       "      <td>152.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>59.48</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.88</td>\n",
       "      <td>102.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>58.81</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.17</td>\n",
       "      <td>67.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>58.25</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.17</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2013-06-08</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>57.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6.30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  hour  month  day_of_week  sunrise  precip_prob  temperature  \\\n",
       "168  2013-06-08     0      6            7        0         0.93        60.44   \n",
       "169  2013-06-08     1      6            7        0         0.92        59.48   \n",
       "170  2013-06-08     2      6            7        0         0.90        58.81   \n",
       "171  2013-06-08     3      6            7        0         0.94        58.25   \n",
       "172  2013-06-08     4      6            7        0         0.83        57.63   \n",
       "\n",
       "     humidity  wind_speed   lag7   lag1  \n",
       "168      0.94        5.84  152.0  152.0  \n",
       "169      0.94        4.88  102.0   71.0  \n",
       "170      0.94        5.17   67.0   58.0  \n",
       "171      0.94        5.17   41.0   17.0  \n",
       "172      0.94        6.30   16.0   25.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train.iloc[:, train.columns != 'rides'], train.iloc[:, train.columns == 'rides'].iloc[:, 0]\n",
    "X_validate, y_validate = validate.iloc[:, validate.columns != 'rides'], validate.iloc[:, validate.columns == 'rides'].iloc[:, 0]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dummy Predictor</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is helpful to start with a heuristic predictor. The type of predictor that can be used without any statistical or machine learning knowledge. We can compare our ML work against this predictor to determine what type of improvement machine learning has added. \n",
    "\n",
    "In this heuristic I am simply making predictions by going back in time 1 year and finding the closest day of the week and resuing that number. That is, I am using the 3rd Wednesday in June 2015 to predict the 3rd Wednesday in June 2016. In the event that that information is not available, I simply take the last available data from the same hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearAgoRegressor(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.X = X.loc[:, ['date', 'hour']]\n",
    "        self.X['date'] = self.X['date'].map(lambda x: pd.to_datetime(x))\n",
    "        self.X['rides'] = y\n",
    "        return self\n",
    "    \n",
    "    def _meaning(self, x):\n",
    "        prev_year = pd.to_datetime(x.date) - pd.DateOffset(years=1)\n",
    "        day_delta = int(prev_year.strftime('%w')) + 1 - x.day_of_week\n",
    "        prev_year = prev_year - pd.Timedelta(days=day_delta)\n",
    "        if not self.X[(self.X.date == prev_year) & (self.X.hour == x.hour)].empty:\n",
    "            return self.X[(self.X.date == prev_year) & (self.X.hour == x.hour)].iloc[0, :].rides\n",
    "        return self.X[(self.X.hour == x.hour)].iloc[-1, :].rides\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        return(X.apply(self._meaning, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=3),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None, steps=[('yearagoregressor', YearAgoRegressor())]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "pipeline = make_pipeline(\n",
    "    YearAgoRegressor()\n",
    ")\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(3), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(train, train.rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-843615.1207858355"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MSE of ~843615 will serve as my baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.columns]\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.func(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['sunrise'])),\n",
    "            ('cat_ohe', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', CustomTransformer(lambda y: y.applymap(lambda x: float(pd.to_datetime(x).year - 2013)))),\n",
    "            ('year_scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed', 'lag7', 'lag1'])),\n",
    "            ('int_scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('rad', Pipeline([\n",
    "            ('rad_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('rad_cos_sin', FeatureUnion([\n",
    "                ('rad_cos', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.cos(x * pi * 2/ x.nunique()), 5)))),\n",
    "                ('rad_sin', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.sin(x * pi * 2/ x.nunique()), 5))))\n",
    "            ]))  \n",
    "        ]))\n",
    "    ])),\n",
    "    ('svr', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  1.2min finished\n",
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=3),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('cat', Pipeline(memory=None,\n",
       "     steps=[('cat_selector', ColumnSelector(columns=['sunrise'])), ('cat_ohe', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "   ...\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'svr__C': [500], 'svr__gamma': [0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'svr__C': [500],\n",
    "          'svr__gamma': [0.1]}\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(3), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-399577.7994155443"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['sunrise'])),\n",
    "            ('cat_ohe', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', CustomTransformer(lambda y: y.applymap(lambda x: float(pd.to_datetime(x).year))))\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed', 'lag7', 'lag1']))\n",
    "        ])),\n",
    "        ('rad', Pipeline([\n",
    "            ('rad_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('rad_cos_sin', FeatureUnion([\n",
    "                ('rad_cos', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.cos(x * pi * 2/ x.nunique()), 5)))),\n",
    "                ('rad_sin', CustomTransformer(lambda y: y.apply(lambda x: np.round(np.sin(x * pi * 2/ x.nunique()), 5))))\n",
    "            ]))  \n",
    "        ]))\n",
    "    ])),\n",
    "    ('rfr', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   13.9s remaining:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   38.2s finished\n",
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('cat', Pipeline(memory=None,\n",
       "     steps=[('cat_selector', ColumnSelector(columns=['sunrise'])), ('cat_ohe', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "   ...s='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'rfr__n_estimators': [500], 'rfr__max_depth': [20], 'rfr__max_features': ['sqrt']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'rfr__n_estimators': [500],\n",
    "          'rfr__max_depth': [20],\n",
    "          'rfr__max_features': ['sqrt'],\n",
    "         }\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(5), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-369508.5522853572"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lag7', 0.3463949735035121)\n",
      "('lag1', 0.17154210262273634)\n",
      "('day_of_week', 0.06590111463786616)\n",
      "('sunrise', 0.06363612025506829)\n",
      "('hour', 0.062128882638282645)\n",
      "('temp', 0.06184890902621661)\n",
      "('sunrise', 0.0584629724357565)\n",
      "('precip', 0.033230805218876835)\n",
      "('humidity', 0.031512837101652216)\n",
      "('date', 0.024000556872802285)\n",
      "('month', 0.0191005571724678)\n",
      "('hour', 0.018753165317310465)\n",
      "('month', 0.017347952947530405)\n",
      "('wind_speed', 0.015106824140427468)\n",
      "('day_of_week', 0.011032226109493358)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(zip(['sunrise', 'sunrise', 'date', 'precip', 'temp',\n",
    "             'humidity', 'wind_speed', 'lag7', 'lag1', 'hour', 'hour', 'day_of_week', 'day_of_week', 'month', 'month']\n",
    "             , clf.best_estimator_.named_steps['rfr'].feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>XG Boost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.applymap(lambda x: float(pd.to_datetime(x).year))\n",
    "\n",
    "class CosExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.unique = X.nunique()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(lambda x: np.round(np.cos(x * pi * 2/ self.unique), 5), axis=1)\n",
    "\n",
    "class SinExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.unique = X.nunique()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(lambda x: np.round(np.sin(x * pi * 2/ self.unique), 5), axis=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', YearExtractor())\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['sunrise', 'precip_prob', 'temperature', 'humidity', 'wind_speed', 'lag7', 'lag1']))\n",
    "        ])),\n",
    "        ('rad', Pipeline([\n",
    "            ('rad_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('rad_cos_sin', FeatureUnion([\n",
    "                ('rad_cos', CosExtractor()),\n",
    "                ('rad_sin', SinExtractor())\n",
    "            ]))  \n",
    "        ]))\n",
    "    ])),\n",
    "    ('xg', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:  3.7min remaining:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('year', Pipeline(memory=None,\n",
       "     steps=[('year_selector', ColumnSelector(columns=['date'])), ('year_extractor', YearExtractor())])), ('int', Pipeline(memory=None,\n",
       "     steps=[('int_selector', ColumnSelector(columns=['sunrise', 'p...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'xg__eta': [0.005], 'xg__max_depth': [5], 'xg__n_estimators': [900, 1100, 1500], 'xg__colsample_bytree': [0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'xg__eta': [.005],\n",
    "          'xg__max_depth': [5],\n",
    "          'xg__n_estimators': [900],\n",
    "          'xg__colsample_bytree': [0.5],\n",
    "         }\n",
    "clf = GridSearchCV(pipeline, params, cv=TimeSeriesSplit(5), scoring='neg_mean_squared_error', n_jobs=-1, verbose=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-296738.1711271276"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xg.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(clf.best_estimator_, 'xg.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lag7', 0.14029376)\n",
      "('temperature', 0.13604605)\n",
      "('lag1', 0.12870187)\n",
      "('wind_speed', 0.10047638)\n",
      "('humidity', 0.083604604)\n",
      "('day_of_week', 0.061969034)\n",
      "('month', 0.058793172)\n",
      "('precip', 0.05188567)\n",
      "('hour', 0.051448986)\n",
      "('hour', 0.045414846)\n",
      "('date', 0.04509726)\n",
      "('day_of_week', 0.04120683)\n",
      "('month', 0.03791187)\n",
      "('sunrise', 0.017149663)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(zip(['date', 'sunrise', 'precip', 'temperature',\n",
    "             'humidity', 'wind_speed', 'lag1', 'lag7', 'hour', 'hour', 'day_of_week', 'day_of_week', 'month', 'month']\n",
    "             , clf.best_estimator_.named_steps['xg'].feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
