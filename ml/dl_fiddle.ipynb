{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, MinMaxScaler\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Dense, Dropout, concatenate, Input\n",
    "from keras.optimizers import RMSprop\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./historic_data.csv')\n",
    "data['actual'] = data['rides']\n",
    "train_cut = int(len(data) * 0.8)\n",
    "validate_cut = int(len(data) * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>icon</th>\n",
       "      <th>precip_prob</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>77.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>75.62</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.93</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.31</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.16</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>72.42</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour  month  day_of_week  sunrise   icon  precip_prob  \\\n",
       "0  2013-06-01     0      6            7        0  clear         0.01   \n",
       "1  2013-06-01     1      6            7        0  clear         0.01   \n",
       "2  2013-06-01     2      6            7        0  clear         0.01   \n",
       "3  2013-06-01     3      6            7        0  clear         0.01   \n",
       "4  2013-06-01     4      6            7        0  clear         0.01   \n",
       "\n",
       "   temperature  humidity  wind_speed  actual  \n",
       "0        77.65      0.61        2.06     152  \n",
       "1        75.62      0.67        1.93     102  \n",
       "2        74.72      0.70        2.31      67  \n",
       "3        73.32      0.76        2.16      41  \n",
       "4        72.42      0.79        1.93      16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data.iloc[:, data.columns != 'rides'], data.iloc[:, data.columns == 'rides'].iloc[:, 0]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.applymap(lambda x: float(pd.to_datetime(x).year))\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.columns]\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.func(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('cat_encoder', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', YearExtractor()),\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['sunrise', 'precip_prob', 'temperature', 'humidity', 'wind_speed', 'actual'])),\n",
    "        ])),\n",
    "    ])),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X.iloc[0:train_cut, :])\n",
    "ft_X = pipeline.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array(y[0:train_cut]).reshape(-1, 1))\n",
    "\n",
    "min_max_y = scaler.transform(np.array(y).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(predictors, response, start, stop, lookback, lag, batch_size=2, shuf=True):\n",
    "    index = start\n",
    "    order = [i for i in range(start, stop+1)]\n",
    "    order_index = 0\n",
    "    if shuf:\n",
    "        shuffle(order)\n",
    "    while True:\n",
    "        if index + batch_size > stop:\n",
    "            samples = np.zeros((stop-index, 1, lookback))\n",
    "            meta = np.zeros((stop-index, len(predictors[0])-1))\n",
    "            targets = np.zeros(stop-index)\n",
    "        else:\n",
    "            samples = np.zeros((batch_size, 1, lookback))\n",
    "            meta = np.zeros((batch_size, len(predictors[0])-1))\n",
    "            targets = np.zeros(batch_size)\n",
    "        for i in range(samples.shape[0]):\n",
    "            samples[i] = predictors[order[order_index]-lookback-lag:order[order_index]-lag, -1].reshape(1, -1)\n",
    "            meta[i] = predictors[order[order_index], :-1]\n",
    "            targets[i] = response[order[order_index]]\n",
    "            order_index += 1\n",
    "\n",
    "        index += batch_size\n",
    "        if index >= stop:\n",
    "            index = start\n",
    "            order = [i for i in range(start, stop+1)]\n",
    "            order_index = 0\n",
    "            if shuf:\n",
    "                shuffle(order)\n",
    "        \n",
    "        yield [samples,meta], targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='my_model9.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "        \n",
    "lookback = 14*24 # seven days\n",
    "lag = 2*24 # one day\n",
    "batch_size = 64\n",
    "train_steps = (train_cut - lookback - lag) // batch_size + 1\n",
    "val_steps = (validate_cut - train_cut) // batch_size + 1\n",
    "\n",
    "\n",
    "train_gen = generator(ft_X, min_max_y, lookback+lag, train_cut, lookback, lag, batch_size)\n",
    "validate_gen = generator(ft_X, min_max_y, train_cut, validate_cut, lookback, lag, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "weather (InputLayer)            (None, 49)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "historical (InputLayer)         (None, 1, 336)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 64)           3200        weather[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_13 (GRU)                    (None, 64)           76992       historical[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 64)           0           dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 128)          0           gru_13[0][0]                     \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 128)          16512       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 128)          0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 64)           8256        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 64)           0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1)            65          dropout_30[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 105,025\n",
      "Trainable params: 105,025\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling1D\n",
    "\n",
    "historical = Input(shape=(1, lookback), name='historical')\n",
    "historical1 = GRU(64, dropout=0.5, recurrent_dropout=0.5, input_shape=(None, ))(historical)\n",
    "\n",
    "weather = Input(shape=(49, ), name='weather')\n",
    "weather1 = Dense(64, activation='relu')(weather)\n",
    "weather1 = Dropout(0.5)(weather1)\n",
    "\n",
    "concat = concatenate([historical1, weather1])\n",
    "concat1 = Dense(128, activation='relu')(concat)\n",
    "concat1 = Dropout(0.5)(concat1)\n",
    "concat1 = Dense(64, activation='relu')(concat1)\n",
    "concat1 = Dropout(0.5)(concat1)\n",
    "output = Dense(1)(concat1)\n",
    "\n",
    "model = Model([historical, weather], output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "492/492 [==============================] - 5s 11ms/step - loss: 0.0148 - mean_absolute_error: 0.0838 - val_loss: 0.0159 - val_mean_absolute_error: 0.0901\n",
      "Epoch 2/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0069 - mean_absolute_error: 0.0585 - val_loss: 0.0109 - val_mean_absolute_error: 0.0734\n",
      "Epoch 3/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0056 - mean_absolute_error: 0.0525 - val_loss: 0.0106 - val_mean_absolute_error: 0.0730\n",
      "Epoch 4/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0050 - mean_absolute_error: 0.0495 - val_loss: 0.0079 - val_mean_absolute_error: 0.0605\n",
      "Epoch 5/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0044 - mean_absolute_error: 0.0470 - val_loss: 0.0088 - val_mean_absolute_error: 0.0632\n",
      "Epoch 6/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0042 - mean_absolute_error: 0.0455 - val_loss: 0.0074 - val_mean_absolute_error: 0.0587\n",
      "Epoch 7/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0040 - mean_absolute_error: 0.0439 - val_loss: 0.0063 - val_mean_absolute_error: 0.0552\n",
      "Epoch 8/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0039 - mean_absolute_error: 0.0434 - val_loss: 0.0073 - val_mean_absolute_error: 0.0609\n",
      "Epoch 9/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0037 - mean_absolute_error: 0.0424 - val_loss: 0.0058 - val_mean_absolute_error: 0.0524\n",
      "Epoch 10/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0036 - mean_absolute_error: 0.0418 - val_loss: 0.0073 - val_mean_absolute_error: 0.0590\n",
      "Epoch 11/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0035 - mean_absolute_error: 0.0410 - val_loss: 0.0044 - val_mean_absolute_error: 0.0468\n",
      "Epoch 12/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0034 - mean_absolute_error: 0.0406 - val_loss: 0.0043 - val_mean_absolute_error: 0.0444\n",
      "Epoch 13/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0033 - mean_absolute_error: 0.0398 - val_loss: 0.0077 - val_mean_absolute_error: 0.0619\n",
      "Epoch 14/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0033 - mean_absolute_error: 0.0398 - val_loss: 0.0041 - val_mean_absolute_error: 0.0410\n",
      "Epoch 15/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0033 - mean_absolute_error: 0.0394 - val_loss: 0.0045 - val_mean_absolute_error: 0.0470\n",
      "Epoch 16/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0032 - mean_absolute_error: 0.0391 - val_loss: 0.0057 - val_mean_absolute_error: 0.0497\n",
      "Epoch 17/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0031 - mean_absolute_error: 0.0379 - val_loss: 0.0039 - val_mean_absolute_error: 0.0434\n",
      "Epoch 18/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0031 - mean_absolute_error: 0.0380 - val_loss: 0.0052 - val_mean_absolute_error: 0.0517\n",
      "Epoch 19/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0030 - mean_absolute_error: 0.0377 - val_loss: 0.0051 - val_mean_absolute_error: 0.0484\n",
      "Epoch 20/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0030 - mean_absolute_error: 0.0373 - val_loss: 0.0036 - val_mean_absolute_error: 0.0391\n",
      "Epoch 21/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0028 - mean_absolute_error: 0.0365 - val_loss: 0.0048 - val_mean_absolute_error: 0.0488\n",
      "Epoch 22/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0030 - mean_absolute_error: 0.0373 - val_loss: 0.0033 - val_mean_absolute_error: 0.0381\n",
      "Epoch 23/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0369 - val_loss: 0.0041 - val_mean_absolute_error: 0.0420\n",
      "Epoch 24/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0028 - mean_absolute_error: 0.0364 - val_loss: 0.0048 - val_mean_absolute_error: 0.0464\n",
      "Epoch 25/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0029 - mean_absolute_error: 0.0366 - val_loss: 0.0053 - val_mean_absolute_error: 0.0480\n",
      "Epoch 26/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0028 - mean_absolute_error: 0.0363 - val_loss: 0.0033 - val_mean_absolute_error: 0.0377\n",
      "Epoch 27/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0028 - mean_absolute_error: 0.0363 - val_loss: 0.0031 - val_mean_absolute_error: 0.0369\n",
      "Epoch 28/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0028 - mean_absolute_error: 0.0362 - val_loss: 0.0042 - val_mean_absolute_error: 0.0440\n",
      "Epoch 29/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0028 - mean_absolute_error: 0.0362 - val_loss: 0.0047 - val_mean_absolute_error: 0.0449\n",
      "Epoch 30/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0027 - mean_absolute_error: 0.0358 - val_loss: 0.0037 - val_mean_absolute_error: 0.0382\n",
      "Epoch 31/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0027 - mean_absolute_error: 0.0357 - val_loss: 0.0041 - val_mean_absolute_error: 0.0410\n",
      "Epoch 32/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0027 - mean_absolute_error: 0.0356 - val_loss: 0.0042 - val_mean_absolute_error: 0.0432\n",
      "Epoch 33/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0027 - mean_absolute_error: 0.0353 - val_loss: 0.0037 - val_mean_absolute_error: 0.0386\n",
      "Epoch 34/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0027 - mean_absolute_error: 0.0354 - val_loss: 0.0041 - val_mean_absolute_error: 0.0434\n",
      "Epoch 35/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0027 - mean_absolute_error: 0.0353 - val_loss: 0.0048 - val_mean_absolute_error: 0.0438\n",
      "Epoch 36/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0027 - mean_absolute_error: 0.0354 - val_loss: 0.0034 - val_mean_absolute_error: 0.0387\n",
      "Epoch 37/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0026 - mean_absolute_error: 0.0352 - val_loss: 0.0054 - val_mean_absolute_error: 0.0493\n",
      "Epoch 38/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0026 - mean_absolute_error: 0.0352 - val_loss: 0.0038 - val_mean_absolute_error: 0.0427\n",
      "Epoch 39/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0027 - mean_absolute_error: 0.0353 - val_loss: 0.0037 - val_mean_absolute_error: 0.0399\n",
      "Epoch 40/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0026 - mean_absolute_error: 0.0350 - val_loss: 0.0041 - val_mean_absolute_error: 0.0427\n",
      "Epoch 41/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0026 - mean_absolute_error: 0.0350 - val_loss: 0.0034 - val_mean_absolute_error: 0.0383\n",
      "Epoch 42/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0027 - mean_absolute_error: 0.0353 - val_loss: 0.0041 - val_mean_absolute_error: 0.0441\n",
      "Epoch 43/75\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0026 - mean_absolute_error: 0.0350 - val_loss: 0.0038 - val_mean_absolute_error: 0.0435\n",
      "Epoch 44/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0026 - mean_absolute_error: 0.0346 - val_loss: 0.0041 - val_mean_absolute_error: 0.0412\n",
      "Epoch 45/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0027 - mean_absolute_error: 0.0354 - val_loss: 0.0045 - val_mean_absolute_error: 0.0431\n",
      "Epoch 46/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0026 - mean_absolute_error: 0.0349 - val_loss: 0.0033 - val_mean_absolute_error: 0.0370\n",
      "Epoch 47/75\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0026 - mean_absolute_error: 0.0349 - val_loss: 0.0037 - val_mean_absolute_error: 0.0388\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=75, \n",
    "                    validation_data=validate_gen, validation_steps=val_steps,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348428635526023.4"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import load_model\n",
    "\n",
    "mmodel = load_model('my_model9.h5')\n",
    "\n",
    "new_gen = generator(ft_X, min_max_y, train_cut, validate_cut, lookback, lag, batch_size, shuf=False)\n",
    "predictions = model.predict_generator(new_gen, steps=val_steps)\n",
    "mean_squared_error(scaler.inverse_transform(predictions), y[train_cut:validate_cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gen = generator(ft_X, y, validate_cut, len(data), lookback, lag, batch_size, shuf=False)\n",
    "predictions = model.predict_generator(new_gen, steps=val_steps)\n",
    "mean_squared_error(predictions, y[validate_cut:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "490/490 [==============================] - 8s 15ms/step - loss: 682392.7240 - mean_absolute_error: 514.1339 - val_loss: 587883.3019 - val_mean_absolute_error: 503.0111\n",
      "Epoch 2/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 331320.1240 - mean_absolute_error: 367.2021 - val_loss: 476153.6919 - val_mean_absolute_error: 454.7355\n",
      "Epoch 3/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 296640.1428 - mean_absolute_error: 342.9276 - val_loss: 442192.5753 - val_mean_absolute_error: 437.0235\n",
      "Epoch 4/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 278983.6530 - mean_absolute_error: 333.3304 - val_loss: 455082.0350 - val_mean_absolute_error: 450.8656\n",
      "Epoch 5/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 263464.7562 - mean_absolute_error: 323.4791 - val_loss: 491753.3197 - val_mean_absolute_error: 461.3687\n",
      "Epoch 6/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 259085.8584 - mean_absolute_error: 320.3556 - val_loss: 332973.2634 - val_mean_absolute_error: 374.5844\n",
      "Epoch 7/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 247913.1503 - mean_absolute_error: 312.6084 - val_loss: 378860.1114 - val_mean_absolute_error: 404.0884\n",
      "Epoch 8/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 244609.3396 - mean_absolute_error: 309.9958 - val_loss: 326364.1974 - val_mean_absolute_error: 367.7570\n",
      "Epoch 9/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 239926.7220 - mean_absolute_error: 305.7648 - val_loss: 294350.4448 - val_mean_absolute_error: 350.0072\n",
      "Epoch 10/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 233924.0696 - mean_absolute_error: 302.4477 - val_loss: 305414.0629 - val_mean_absolute_error: 351.9973\n",
      "Epoch 11/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 231337.6808 - mean_absolute_error: 299.3713 - val_loss: 339724.6960 - val_mean_absolute_error: 371.7613\n",
      "Epoch 12/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 227214.8147 - mean_absolute_error: 298.4708 - val_loss: 268211.9426 - val_mean_absolute_error: 331.1640\n",
      "Epoch 13/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 231743.0663 - mean_absolute_error: 299.2165 - val_loss: 310441.9945 - val_mean_absolute_error: 358.6022\n",
      "Epoch 14/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 226577.2515 - mean_absolute_error: 295.5565 - val_loss: 318462.0441 - val_mean_absolute_error: 366.8032\n",
      "Epoch 15/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 223765.9453 - mean_absolute_error: 295.8800 - val_loss: 268480.0550 - val_mean_absolute_error: 328.9379\n",
      "Epoch 16/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 223965.5089 - mean_absolute_error: 294.1139 - val_loss: 266990.9517 - val_mean_absolute_error: 328.9123\n",
      "Epoch 17/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 222873.5036 - mean_absolute_error: 292.4828 - val_loss: 300511.1391 - val_mean_absolute_error: 348.6522\n",
      "Epoch 18/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 220190.9718 - mean_absolute_error: 291.2141 - val_loss: 236089.4456 - val_mean_absolute_error: 303.3146\n",
      "Epoch 19/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 217478.5248 - mean_absolute_error: 288.4528 - val_loss: 230627.8706 - val_mean_absolute_error: 301.8569\n",
      "Epoch 20/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 219335.7040 - mean_absolute_error: 289.5620 - val_loss: 280408.3149 - val_mean_absolute_error: 333.8599\n",
      "Epoch 21/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 216914.2064 - mean_absolute_error: 286.9903 - val_loss: 259918.8738 - val_mean_absolute_error: 324.9306\n",
      "Epoch 22/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 212782.2049 - mean_absolute_error: 285.0348 - val_loss: 246044.2800 - val_mean_absolute_error: 308.2019\n",
      "Epoch 23/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 215678.0825 - mean_absolute_error: 285.3304 - val_loss: 298968.9796 - val_mean_absolute_error: 358.4495\n",
      "Epoch 24/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 212323.0224 - mean_absolute_error: 283.8287 - val_loss: 255884.9153 - val_mean_absolute_error: 321.1557\n",
      "Epoch 25/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 210213.6461 - mean_absolute_error: 283.6948 - val_loss: 245934.4295 - val_mean_absolute_error: 313.5879\n",
      "Epoch 26/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 206615.1154 - mean_absolute_error: 279.9472 - val_loss: 247700.0087 - val_mean_absolute_error: 315.8077\n",
      "Epoch 27/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 212420.4376 - mean_absolute_error: 283.1079 - val_loss: 258354.7012 - val_mean_absolute_error: 326.9802\n",
      "Epoch 28/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 209304.1425 - mean_absolute_error: 281.2661 - val_loss: 217655.6299 - val_mean_absolute_error: 291.4212\n",
      "Epoch 29/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 208705.8572 - mean_absolute_error: 280.6116 - val_loss: 248193.7244 - val_mean_absolute_error: 318.5926\n",
      "Epoch 30/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 205966.0746 - mean_absolute_error: 279.3681 - val_loss: 270358.1008 - val_mean_absolute_error: 339.3355\n",
      "Epoch 31/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 203085.1734 - mean_absolute_error: 279.1429 - val_loss: 218518.8649 - val_mean_absolute_error: 291.0690\n",
      "Epoch 32/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 206938.5083 - mean_absolute_error: 280.6209 - val_loss: 207511.2114 - val_mean_absolute_error: 281.3246\n",
      "Epoch 33/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 206795.5274 - mean_absolute_error: 279.7613 - val_loss: 229090.6728 - val_mean_absolute_error: 300.5124\n",
      "Epoch 34/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 203857.1360 - mean_absolute_error: 276.6770 - val_loss: 217947.7854 - val_mean_absolute_error: 291.3051\n",
      "Epoch 35/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 202086.6988 - mean_absolute_error: 276.6047 - val_loss: 214796.8355 - val_mean_absolute_error: 289.5414\n",
      "Epoch 36/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 207675.7274 - mean_absolute_error: 277.5389 - val_loss: 238808.6119 - val_mean_absolute_error: 310.2813\n",
      "Epoch 37/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 200507.7296 - mean_absolute_error: 277.2621 - val_loss: 235765.7015 - val_mean_absolute_error: 307.4883\n",
      "Epoch 38/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 207502.8542 - mean_absolute_error: 279.2815 - val_loss: 227247.0389 - val_mean_absolute_error: 297.7534\n",
      "Epoch 39/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 204242.3640 - mean_absolute_error: 276.4737 - val_loss: 238506.9930 - val_mean_absolute_error: 309.9515\n",
      "Epoch 40/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 198709.9657 - mean_absolute_error: 274.0761 - val_loss: 219865.1275 - val_mean_absolute_error: 292.6806\n",
      "Epoch 41/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 196549.0810 - mean_absolute_error: 272.3392 - val_loss: 201568.2106 - val_mean_absolute_error: 273.9183\n",
      "Epoch 42/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 198330.8351 - mean_absolute_error: 273.8916 - val_loss: 226114.2753 - val_mean_absolute_error: 297.9685\n",
      "Epoch 43/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 200272.7596 - mean_absolute_error: 273.6463 - val_loss: 246722.8205 - val_mean_absolute_error: 312.5392\n",
      "Epoch 44/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 194922.5974 - mean_absolute_error: 271.9431 - val_loss: 207194.7490 - val_mean_absolute_error: 278.8356\n",
      "Epoch 45/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 202579.9679 - mean_absolute_error: 275.9288 - val_loss: 213053.2846 - val_mean_absolute_error: 285.5372\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/490 [==============================] - 4s 8ms/step - loss: 196435.5267 - mean_absolute_error: 274.2242 - val_loss: 200480.7185 - val_mean_absolute_error: 278.8434\n",
      "Epoch 47/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 197109.7753 - mean_absolute_error: 272.6228 - val_loss: 204682.2665 - val_mean_absolute_error: 274.7608\n",
      "Epoch 48/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 197978.6647 - mean_absolute_error: 273.7065 - val_loss: 214842.1845 - val_mean_absolute_error: 286.3170\n",
      "Epoch 49/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 194697.7019 - mean_absolute_error: 271.0265 - val_loss: 193714.5939 - val_mean_absolute_error: 274.8369\n",
      "Epoch 50/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 194138.8524 - mean_absolute_error: 269.6350 - val_loss: 202435.9020 - val_mean_absolute_error: 276.9298\n",
      "Epoch 51/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 192966.9346 - mean_absolute_error: 269.5530 - val_loss: 205036.2863 - val_mean_absolute_error: 275.9530\n",
      "Epoch 52/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 194393.7912 - mean_absolute_error: 270.9491 - val_loss: 193704.6056 - val_mean_absolute_error: 272.4947\n",
      "Epoch 53/100\n",
      "490/490 [==============================] - 4s 9ms/step - loss: 191460.7565 - mean_absolute_error: 269.3390 - val_loss: 222844.8112 - val_mean_absolute_error: 294.1947\n",
      "Epoch 54/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 200506.7779 - mean_absolute_error: 273.1241 - val_loss: 230101.3988 - val_mean_absolute_error: 306.6769\n",
      "Epoch 55/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 198068.2381 - mean_absolute_error: 272.0390 - val_loss: 195717.2511 - val_mean_absolute_error: 275.4585\n",
      "Epoch 56/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 197105.2505 - mean_absolute_error: 273.4700 - val_loss: 200117.1817 - val_mean_absolute_error: 275.3943\n",
      "Epoch 57/100\n",
      "490/490 [==============================] - 4s 9ms/step - loss: 194525.2687 - mean_absolute_error: 270.5340 - val_loss: 205561.3487 - val_mean_absolute_error: 280.1268\n",
      "Epoch 58/100\n",
      "490/490 [==============================] - 5s 9ms/step - loss: 194072.0463 - mean_absolute_error: 269.3336 - val_loss: 229584.5692 - val_mean_absolute_error: 300.5264\n",
      "Epoch 59/100\n",
      "490/490 [==============================] - 4s 9ms/step - loss: 194502.7532 - mean_absolute_error: 269.3389 - val_loss: 194227.4070 - val_mean_absolute_error: 269.2275\n",
      "Epoch 60/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 194688.7944 - mean_absolute_error: 268.5349 - val_loss: 204024.5983 - val_mean_absolute_error: 278.3411\n",
      "Epoch 61/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 192508.9717 - mean_absolute_error: 269.9646 - val_loss: 189672.5816 - val_mean_absolute_error: 268.1078\n",
      "Epoch 62/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 194076.8008 - mean_absolute_error: 270.0379 - val_loss: 197050.4310 - val_mean_absolute_error: 271.0139\n",
      "Epoch 63/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 192409.2854 - mean_absolute_error: 267.4520 - val_loss: 204831.9332 - val_mean_absolute_error: 281.6481\n",
      "Epoch 64/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 191153.0382 - mean_absolute_error: 267.6793 - val_loss: 197967.6594 - val_mean_absolute_error: 271.6352\n",
      "Epoch 65/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 192565.5752 - mean_absolute_error: 269.1096 - val_loss: 188573.5397 - val_mean_absolute_error: 264.4390\n",
      "Epoch 66/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 193089.4245 - mean_absolute_error: 268.0916 - val_loss: 216673.8321 - val_mean_absolute_error: 287.2279\n",
      "Epoch 67/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 187605.1517 - mean_absolute_error: 267.1561 - val_loss: 190091.4362 - val_mean_absolute_error: 268.3903\n",
      "Epoch 68/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 188562.0312 - mean_absolute_error: 265.8351 - val_loss: 193113.7896 - val_mean_absolute_error: 265.8392\n",
      "Epoch 69/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 189864.9252 - mean_absolute_error: 266.6736 - val_loss: 189652.3447 - val_mean_absolute_error: 268.1202\n",
      "Epoch 70/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 188486.9718 - mean_absolute_error: 266.8597 - val_loss: 192096.5892 - val_mean_absolute_error: 270.5177\n",
      "Epoch 71/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 192694.8078 - mean_absolute_error: 267.4790 - val_loss: 198604.1393 - val_mean_absolute_error: 274.7489\n",
      "Epoch 72/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 190583.3850 - mean_absolute_error: 267.7534 - val_loss: 188445.3836 - val_mean_absolute_error: 263.3791\n",
      "Epoch 73/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 189270.1018 - mean_absolute_error: 266.5180 - val_loss: 194718.8615 - val_mean_absolute_error: 270.7992\n",
      "Epoch 74/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 188601.2691 - mean_absolute_error: 266.8132 - val_loss: 186350.9747 - val_mean_absolute_error: 266.6007\n",
      "Epoch 75/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 191256.9602 - mean_absolute_error: 268.1630 - val_loss: 202188.1584 - val_mean_absolute_error: 275.8100\n",
      "Epoch 76/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 189768.5353 - mean_absolute_error: 268.3885 - val_loss: 195656.6895 - val_mean_absolute_error: 274.2807\n",
      "Epoch 77/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 191387.4082 - mean_absolute_error: 266.7980 - val_loss: 206431.3369 - val_mean_absolute_error: 273.9127\n",
      "Epoch 78/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 189550.3596 - mean_absolute_error: 265.8312 - val_loss: 196229.2384 - val_mean_absolute_error: 268.5286\n",
      "Epoch 79/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 188798.8190 - mean_absolute_error: 265.7329 - val_loss: 183925.1179 - val_mean_absolute_error: 261.2273\n",
      "Epoch 80/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 190111.8759 - mean_absolute_error: 267.0318 - val_loss: 208782.1814 - val_mean_absolute_error: 279.4110\n",
      "Epoch 81/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 183327.8648 - mean_absolute_error: 263.3601 - val_loss: 220749.3661 - val_mean_absolute_error: 289.2968\n",
      "Epoch 82/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 188213.6214 - mean_absolute_error: 265.1979 - val_loss: 181931.8862 - val_mean_absolute_error: 261.3152\n",
      "Epoch 83/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 183767.5345 - mean_absolute_error: 264.1441 - val_loss: 193615.2920 - val_mean_absolute_error: 268.6908\n",
      "Epoch 84/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 190913.5408 - mean_absolute_error: 265.3270 - val_loss: 187767.3602 - val_mean_absolute_error: 263.8655\n",
      "Epoch 85/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 188378.8887 - mean_absolute_error: 266.6207 - val_loss: 184932.6206 - val_mean_absolute_error: 260.7614\n",
      "Epoch 86/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 182311.3802 - mean_absolute_error: 263.0719 - val_loss: 198981.4473 - val_mean_absolute_error: 271.7119\n",
      "Epoch 87/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 187126.7731 - mean_absolute_error: 264.3332 - val_loss: 187696.4469 - val_mean_absolute_error: 264.0310\n",
      "Epoch 88/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 190354.0028 - mean_absolute_error: 266.2341 - val_loss: 188182.2079 - val_mean_absolute_error: 263.9854\n",
      "Epoch 89/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 189774.5825 - mean_absolute_error: 265.5054 - val_loss: 188726.2792 - val_mean_absolute_error: 266.7595\n",
      "Epoch 90/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 190116.9122 - mean_absolute_error: 266.3913 - val_loss: 183647.3389 - val_mean_absolute_error: 258.4379\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/490 [==============================] - 4s 8ms/step - loss: 186942.6469 - mean_absolute_error: 266.7967 - val_loss: 191787.9625 - val_mean_absolute_error: 265.7032\n",
      "Epoch 92/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 182464.8916 - mean_absolute_error: 261.7419 - val_loss: 198536.0418 - val_mean_absolute_error: 275.5772\n",
      "Epoch 93/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 184372.5181 - mean_absolute_error: 262.8973 - val_loss: 195068.3933 - val_mean_absolute_error: 272.4435\n",
      "Epoch 94/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 183119.4307 - mean_absolute_error: 262.9034 - val_loss: 186720.7375 - val_mean_absolute_error: 265.4643\n",
      "Epoch 95/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 182852.9956 - mean_absolute_error: 262.9579 - val_loss: 190567.2795 - val_mean_absolute_error: 266.8952\n",
      "Epoch 96/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 180043.1581 - mean_absolute_error: 261.9371 - val_loss: 202716.1727 - val_mean_absolute_error: 274.2469\n",
      "Epoch 97/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 181635.0308 - mean_absolute_error: 261.4346 - val_loss: 199798.6307 - val_mean_absolute_error: 270.8088\n",
      "Epoch 98/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 175581.3743 - mean_absolute_error: 257.9826 - val_loss: 192871.1154 - val_mean_absolute_error: 267.8258\n",
      "Epoch 99/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 178729.7568 - mean_absolute_error: 259.9888 - val_loss: 180985.0746 - val_mean_absolute_error: 260.2986\n",
      "Epoch 100/100\n",
      "490/490 [==============================] - 4s 8ms/step - loss: 186685.5777 - mean_absolute_error: 263.6134 - val_loss: 179562.0804 - val_mean_absolute_error: 259.9049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2645bf36f60>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='my_model11.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "        \n",
    "lookback = 21*24 # seven days\n",
    "lag = 2*24 # one day\n",
    "batch_size = 64\n",
    "train_steps = (train_cut - lookback - lag) // batch_size + 1\n",
    "val_steps = (validate_cut - train_cut) // batch_size + 1\n",
    "\n",
    "train_gen = generator(ft_X, y, lookback+lag, train_cut, lookback, lag, batch_size)\n",
    "validate_gen = generator(ft_X, y, train_cut, validate_cut, lookback, lag, batch_size)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling1D\n",
    "\n",
    "historical = Input(shape=(1, lookback), name='historical')\n",
    "historical1 = GRU(128, dropout=0.5, recurrent_dropout=0.5, input_shape=(None, ))(historical)\n",
    "historical1 = Dense(256, activation='relu')(historical1)\n",
    "historical1 = Dropout(0.5)(historical1)\n",
    "\n",
    "weather = Input(shape=(49, ), name='weather')\n",
    "weather1 = Dense(64, activation='relu')(weather)\n",
    "weather1 = Dropout(0.5)(weather1)\n",
    "\n",
    "concat = concatenate([historical1, weather1])\n",
    "concat1 = Dense(128, activation='relu')(concat)\n",
    "concat1 = Dropout(0.5)(concat1)\n",
    "concat1 = Dense(64, activation='relu')(concat1)\n",
    "concat1 = Dropout(0.5)(concat1)\n",
    "output = Dense(1)(concat1)\n",
    "\n",
    "model = Model([historical, weather], output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=100, \n",
    "                    validation_data=validate_gen, validation_steps=val_steps,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179568.40411785862"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmodel = load_model('my_model11.h5')\n",
    "\n",
    "new_gen = generator(ft_X, y, train_cut, validate_cut, lookback, lag, batch_size, shuf=False)\n",
    "predictions = mmodel.predict_generator(new_gen, steps=val_steps)\n",
    "mean_squared_error(predictions, y[train_cut:validate_cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254101.35173929893"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gen = generator(ft_X, y, validate_cut, len(data), lookback, lag, batch_size, shuf=False)\n",
    "predictions = mmodel.predict_generator(new_gen, steps=val_steps)\n",
    "mean_squared_error(predictions, y[validate_cut:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "232/232 [==============================] - 12s 51ms/step - loss: 2647560.4725 - mean_absolute_error: 1119.0565 - val_loss: 2271739.0182 - val_mean_absolute_error: 999.8818\n",
      "Epoch 2/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 916912.8461 - mean_absolute_error: 626.6592 - val_loss: 1096489.8425 - val_mean_absolute_error: 687.2201\n",
      "Epoch 3/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 699748.0468 - mean_absolute_error: 531.8061 - val_loss: 803007.7762 - val_mean_absolute_error: 580.5482\n",
      "Epoch 4/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 585353.7774 - mean_absolute_error: 491.0125 - val_loss: 761951.9875 - val_mean_absolute_error: 584.3167\n",
      "Epoch 5/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 542931.7429 - mean_absolute_error: 464.3577 - val_loss: 617971.7784 - val_mean_absolute_error: 520.0919\n",
      "Epoch 6/75\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 522199.4379 - mean_absolute_error: 456.6328 - val_loss: 525652.1598 - val_mean_absolute_error: 479.9074\n",
      "Epoch 7/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 488627.0618 - mean_absolute_error: 441.4681 - val_loss: 530064.7610 - val_mean_absolute_error: 487.1523\n",
      "Epoch 8/75\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 488077.0806 - mean_absolute_error: 437.7035 - val_loss: 473373.2329 - val_mean_absolute_error: 462.9612\n",
      "Epoch 9/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 464420.8434 - mean_absolute_error: 426.6218 - val_loss: 434697.0654 - val_mean_absolute_error: 438.7523\n",
      "Epoch 10/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 454622.3874 - mean_absolute_error: 424.3030 - val_loss: 493558.8042 - val_mean_absolute_error: 477.6220\n",
      "Epoch 11/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 440499.1068 - mean_absolute_error: 416.4247 - val_loss: 414139.8122 - val_mean_absolute_error: 430.8205\n",
      "Epoch 12/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 439801.7230 - mean_absolute_error: 415.0384 - val_loss: 404056.9636 - val_mean_absolute_error: 424.1137\n",
      "Epoch 13/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 444887.3072 - mean_absolute_error: 417.1210 - val_loss: 346185.8255 - val_mean_absolute_error: 387.5823\n",
      "Epoch 14/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 446104.4601 - mean_absolute_error: 416.5605 - val_loss: 355541.9844 - val_mean_absolute_error: 395.5576\n",
      "Epoch 15/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 437259.1941 - mean_absolute_error: 412.2125 - val_loss: 409417.4961 - val_mean_absolute_error: 421.3692\n",
      "Epoch 16/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 439803.0205 - mean_absolute_error: 413.8752 - val_loss: 384377.1405 - val_mean_absolute_error: 409.9743\n",
      "Epoch 17/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 438061.4251 - mean_absolute_error: 412.8914 - val_loss: 370918.9822 - val_mean_absolute_error: 406.2701\n",
      "Epoch 18/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 429590.4644 - mean_absolute_error: 408.1698 - val_loss: 383824.9380 - val_mean_absolute_error: 412.2441\n",
      "Epoch 19/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 423810.0279 - mean_absolute_error: 406.4023 - val_loss: 332309.7645 - val_mean_absolute_error: 378.0572\n",
      "Epoch 20/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 430459.2882 - mean_absolute_error: 407.6692 - val_loss: 352441.2856 - val_mean_absolute_error: 396.1075\n",
      "Epoch 21/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 426183.1724 - mean_absolute_error: 407.6416 - val_loss: 356289.8622 - val_mean_absolute_error: 398.0190\n",
      "Epoch 22/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 429612.7357 - mean_absolute_error: 406.3738 - val_loss: 383646.2257 - val_mean_absolute_error: 409.2836\n",
      "Epoch 23/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 419570.3763 - mean_absolute_error: 403.7631 - val_loss: 330107.9146 - val_mean_absolute_error: 381.2506\n",
      "Epoch 24/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 418804.2707 - mean_absolute_error: 403.3381 - val_loss: 308446.2255 - val_mean_absolute_error: 365.1363\n",
      "Epoch 25/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 426298.9041 - mean_absolute_error: 406.8583 - val_loss: 301790.8224 - val_mean_absolute_error: 364.8035\n",
      "Epoch 26/75\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 412019.3396 - mean_absolute_error: 400.5556 - val_loss: 310097.0624 - val_mean_absolute_error: 364.9447\n",
      "Epoch 27/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 421309.8575 - mean_absolute_error: 402.1422 - val_loss: 280242.7404 - val_mean_absolute_error: 346.6191\n",
      "Epoch 28/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 410337.7076 - mean_absolute_error: 401.2335 - val_loss: 293707.1347 - val_mean_absolute_error: 359.1759\n",
      "Epoch 29/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 413334.2508 - mean_absolute_error: 399.5810 - val_loss: 309393.7146 - val_mean_absolute_error: 369.1762\n",
      "Epoch 30/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 413531.5459 - mean_absolute_error: 402.9130 - val_loss: 322535.2107 - val_mean_absolute_error: 380.1764\n",
      "Epoch 31/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 418479.3781 - mean_absolute_error: 402.8153 - val_loss: 334628.2237 - val_mean_absolute_error: 382.3398\n",
      "Epoch 32/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 403912.6333 - mean_absolute_error: 396.2191 - val_loss: 293300.6004 - val_mean_absolute_error: 353.0237\n",
      "Epoch 33/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 404344.8126 - mean_absolute_error: 395.1934 - val_loss: 292841.3380 - val_mean_absolute_error: 356.9437\n",
      "Epoch 34/75\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 407641.1362 - mean_absolute_error: 396.8205 - val_loss: 264760.9489 - val_mean_absolute_error: 333.6274\n",
      "Epoch 35/75\n",
      "232/232 [==============================] - 3s 11ms/step - loss: 418043.5668 - mean_absolute_error: 400.1183 - val_loss: 298988.1842 - val_mean_absolute_error: 364.6614\n",
      "Epoch 36/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 408620.6477 - mean_absolute_error: 395.8541 - val_loss: 268876.2137 - val_mean_absolute_error: 342.1686\n",
      "Epoch 37/75\n",
      "232/232 [==============================] - 3s 11ms/step - loss: 412535.6090 - mean_absolute_error: 399.0100 - val_loss: 283569.9278 - val_mean_absolute_error: 347.8898\n",
      "Epoch 38/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 400047.5010 - mean_absolute_error: 395.7230 - val_loss: 339815.4283 - val_mean_absolute_error: 399.0989\n",
      "Epoch 39/75\n",
      "232/232 [==============================] - 3s 11ms/step - loss: 396731.6935 - mean_absolute_error: 393.7486 - val_loss: 294132.6964 - val_mean_absolute_error: 357.8677\n",
      "Epoch 40/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 409786.3073 - mean_absolute_error: 396.3562 - val_loss: 284536.3092 - val_mean_absolute_error: 350.0387\n",
      "Epoch 41/75\n",
      "232/232 [==============================] - 3s 11ms/step - loss: 408351.4761 - mean_absolute_error: 398.6768 - val_loss: 275607.3292 - val_mean_absolute_error: 345.2901\n",
      "Epoch 42/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 402877.6696 - mean_absolute_error: 394.1468 - val_loss: 261448.6585 - val_mean_absolute_error: 336.7178\n",
      "Epoch 43/75\n",
      "232/232 [==============================] - 3s 11ms/step - loss: 407378.4888 - mean_absolute_error: 398.1617 - val_loss: 268989.3913 - val_mean_absolute_error: 339.1739\n",
      "Epoch 44/75\n",
      "232/232 [==============================] - 3s 11ms/step - loss: 406080.3769 - mean_absolute_error: 395.9692 - val_loss: 295871.3973 - val_mean_absolute_error: 366.5831\n",
      "Epoch 45/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 392197.5015 - mean_absolute_error: 388.6092 - val_loss: 254947.3141 - val_mean_absolute_error: 334.2299\n",
      "Epoch 46/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 3s 11ms/step - loss: 393467.4135 - mean_absolute_error: 389.4413 - val_loss: 265451.7428 - val_mean_absolute_error: 342.2583\n",
      "Epoch 47/75\n",
      "232/232 [==============================] - 3s 13ms/step - loss: 395960.4228 - mean_absolute_error: 390.9776 - val_loss: 267444.1800 - val_mean_absolute_error: 345.1954\n",
      "Epoch 48/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 394822.9463 - mean_absolute_error: 390.7807 - val_loss: 277899.9963 - val_mean_absolute_error: 343.8997\n",
      "Epoch 49/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 402372.2999 - mean_absolute_error: 394.9073 - val_loss: 322462.1929 - val_mean_absolute_error: 380.7220\n",
      "Epoch 50/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 409008.5087 - mean_absolute_error: 397.2880 - val_loss: 278677.8664 - val_mean_absolute_error: 349.3607\n",
      "Epoch 51/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 391394.7297 - mean_absolute_error: 387.6124 - val_loss: 254269.3001 - val_mean_absolute_error: 333.2449\n",
      "Epoch 52/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 398335.7360 - mean_absolute_error: 394.0697 - val_loss: 238474.7968 - val_mean_absolute_error: 315.8866\n",
      "Epoch 53/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 390042.3043 - mean_absolute_error: 388.0446 - val_loss: 254130.0422 - val_mean_absolute_error: 331.4064\n",
      "Epoch 54/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 395778.1281 - mean_absolute_error: 391.7775 - val_loss: 251568.2153 - val_mean_absolute_error: 328.4046\n",
      "Epoch 55/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 410743.3440 - mean_absolute_error: 396.9758 - val_loss: 231688.4540 - val_mean_absolute_error: 314.1797\n",
      "Epoch 56/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 389251.5888 - mean_absolute_error: 389.0573 - val_loss: 280249.7935 - val_mean_absolute_error: 351.5522\n",
      "Epoch 57/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 390941.4391 - mean_absolute_error: 390.6822 - val_loss: 230832.7358 - val_mean_absolute_error: 316.9674\n",
      "Epoch 58/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 393917.2517 - mean_absolute_error: 390.1276 - val_loss: 268985.0742 - val_mean_absolute_error: 347.6904\n",
      "Epoch 59/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 399709.1623 - mean_absolute_error: 392.8393 - val_loss: 244922.6682 - val_mean_absolute_error: 321.6748\n",
      "Epoch 60/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 394612.3687 - mean_absolute_error: 390.9553 - val_loss: 300561.3857 - val_mean_absolute_error: 366.1489\n",
      "Epoch 61/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 383345.3205 - mean_absolute_error: 390.0557 - val_loss: 245086.8151 - val_mean_absolute_error: 331.4382\n",
      "Epoch 62/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 389072.7755 - mean_absolute_error: 388.8661 - val_loss: 231650.4118 - val_mean_absolute_error: 316.6329\n",
      "Epoch 63/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 398238.5388 - mean_absolute_error: 389.4800 - val_loss: 275776.2075 - val_mean_absolute_error: 353.3478\n",
      "Epoch 64/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 387281.3639 - mean_absolute_error: 388.8238 - val_loss: 260451.9200 - val_mean_absolute_error: 341.7153\n",
      "Epoch 65/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 399373.6220 - mean_absolute_error: 394.0841 - val_loss: 276120.8775 - val_mean_absolute_error: 358.0649\n",
      "Epoch 66/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 386964.8838 - mean_absolute_error: 387.6447 - val_loss: 228906.5372 - val_mean_absolute_error: 319.0483\n",
      "Epoch 67/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 386908.2966 - mean_absolute_error: 388.2453 - val_loss: 222157.0849 - val_mean_absolute_error: 309.9075\n",
      "Epoch 68/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 391958.0212 - mean_absolute_error: 387.6716 - val_loss: 243722.2774 - val_mean_absolute_error: 328.5816\n",
      "Epoch 69/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 390456.5631 - mean_absolute_error: 390.9336 - val_loss: 251510.2794 - val_mean_absolute_error: 333.5876\n",
      "Epoch 70/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 384680.0890 - mean_absolute_error: 387.1792 - val_loss: 235529.4747 - val_mean_absolute_error: 326.2223\n",
      "Epoch 71/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 384195.7699 - mean_absolute_error: 388.6992 - val_loss: 234420.2101 - val_mean_absolute_error: 322.5197\n",
      "Epoch 72/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 391199.6457 - mean_absolute_error: 390.9465 - val_loss: 227668.7444 - val_mean_absolute_error: 317.3837\n",
      "Epoch 73/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 392259.9479 - mean_absolute_error: 390.5139 - val_loss: 215946.6814 - val_mean_absolute_error: 301.9832\n",
      "Epoch 74/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 384304.3770 - mean_absolute_error: 387.1188 - val_loss: 216757.1335 - val_mean_absolute_error: 305.7071\n",
      "Epoch 75/75\n",
      "232/232 [==============================] - 3s 12ms/step - loss: 380948.0452 - mean_absolute_error: 388.9340 - val_loss: 215997.9666 - val_mean_absolute_error: 303.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264c5c1e6a0>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='my_model14all.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "        \n",
    "lookback = 90*24 # seven days\n",
    "lag = 2*24 # one day\n",
    "batch_size = 128\n",
    "train_steps = (train_cut - lookback - lag) // batch_size + 1\n",
    "val_steps = (validate_cut - train_cut) // batch_size + 1\n",
    "\n",
    "train_gen = generator(ft_X, y, lookback+lag, validate_cut, lookback, lag, batch_size)\n",
    "validate_gen = generator(ft_X, y, train_cut, validate_cut, lookback, lag, batch_size)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling1D\n",
    "\n",
    "historical = Input(shape=(1, lookback), name='historical')\n",
    "historical1 = GRU(16, dropout=0.5, recurrent_dropout=0.5, input_shape=(None, ))(historical)\n",
    "\n",
    "weather = Input(shape=(49, ), name='weather')\n",
    "weather1 = Dense(16, activation='relu')(weather)\n",
    "weather1 = Dropout(0.5)(weather1)\n",
    "\n",
    "concat = concatenate([historical1, weather1])\n",
    "concat1 = Dense(32, activation='relu')(concat)\n",
    "concat1 = Dropout(0.5)(concat1)\n",
    "concat1 = Dense(32, activation='relu')(concat1)\n",
    "concat1 = Dropout(0.5)(concat1)\n",
    "output = Dense(1)(concat1)\n",
    "\n",
    "model = Model([historical, weather], output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=75,\n",
    "                     validation_data=validate_gen, validation_steps=val_steps,\n",
    "                     callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216115.5839459362"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mmodel = load_model('my_model14all.h5')\n",
    "\n",
    "new_gen = generator(ft_X, y, train_cut, validate_cut, lookback, lag, batch_size, shuf=False)\n",
    "predictions = model.predict_generator(new_gen, steps=val_steps)\n",
    "mean_squared_error(predictions, y[train_cut:validate_cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362357.8857199827"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_gen = generator(ft_X, y, validate_cut, len(data), lookback, lag, batch_size, shuf=False)\n",
    "predictions = model.predict_generator(new_gen, steps=val_steps)\n",
    "mean_squared_error(predictions, y[validate_cut:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "historical (InputLayer)         (None, 1, 504)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_20 (GRU)                    (None, 128)          243072      historical[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weather (InputLayer)            (None, 49)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 256)          33024       gru_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 64)           3200        weather[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 256)          0           dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 64)           0           dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 320)          0           dropout_51[0][0]                 \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 256)          82176       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 256)          0           dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 128)          32896       dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 128)          0           dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 1)            129         dropout_54[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 394,497\n",
      "Trainable params: 394,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
