{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, MinMaxScaler, StandardScaler\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import GRU, Dense, Dropout, concatenate, Input\n",
    "from keras.optimizers import RMSprop\n",
    "from random import shuffle\n",
    "import warnings\n",
    "import holidays\n",
    "from datetime import timedelta\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv('./actuals.csv')\n",
    "\n",
    "\n",
    "train_cut = int(len(data) * 0.8)\n",
    "validate_cut = int(len(data) * 0.9)\n",
    "test_cut = int(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>icon</th>\n",
       "      <th>precip_prob</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>77.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>75.62</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.93</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.31</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.16</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-06-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>72.42</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  sunrise   icon  precip_prob  temperature  humidity  \\\n",
       "0  2013-06-01 00:00:00        0  clear         0.01        77.65      0.61   \n",
       "1  2013-06-01 01:00:00        0  clear         0.01        75.62      0.67   \n",
       "2  2013-06-01 02:00:00        0  clear         0.01        74.72      0.70   \n",
       "3  2013-06-01 03:00:00        0  clear         0.01        73.32      0.76   \n",
       "4  2013-06-01 04:00:00        0  clear         0.01        72.42      0.79   \n",
       "\n",
       "   wind_speed  rides  \n",
       "0        2.06    152  \n",
       "1        1.93    102  \n",
       "2        2.31     67  \n",
       "3        2.16     41  \n",
       "4        1.93     16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data, data['rides']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    152\n",
       "1    102\n",
       "2     67\n",
       "3     41\n",
       "4     16\n",
       "Name: rides, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define Custom Transformers and Pipelines</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HolidaySelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        hd = [date for date, name in holidays.US(years=[2013, 2014, 2015, 2016, 2017, 2018]).items()\n",
    "                        if name.startswith((\"New Year's Day\", \"Washington's Birthday\", \"Memorial Day\", \"Independence Date\",\n",
    "                        \"Labor Day\", \"Thanksgiving\", \"Christmas Day\"))]\n",
    "        hd_eve = [day - timedelta(days=1) for day in hd]\n",
    "        hd.extend(hd_eve)\n",
    "        self.h = [str(date) for date in hd]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[['date']].applymap(lambda x: int(pd.to_datetime(x).strftime('%Y-%m-%d') in self.h))\n",
    "    \n",
    "class DateTimeExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, extract):\n",
    "        self.extract = extract\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X[['date']].applymap(lambda x: float(getattr(pd.to_datetime(x), self.extract)))\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('onehot_pipeline', Pipeline([\n",
    "            ('onehot_union', FeatureUnion([\n",
    "                ('hour', DateTimeExtractor('hour')),\n",
    "                ('month', DateTimeExtractor('month')), \n",
    "                ('dayofweek', DateTimeExtractor('dayofweek')), \n",
    "                ('categories', ColumnSelector(['sunrise', 'icon'])),\n",
    "                ('holiday', HolidaySelector()),\n",
    "            ])),\n",
    "            ('onehot_encoder', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('float_pipeline', Pipeline([\n",
    "            ('float_union', FeatureUnion([\n",
    "                ('year', DateTimeExtractor('year')),\n",
    "                ('floats', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed'])),\n",
    "            ])),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]))\n",
    "    ]))\n",
    "])\n",
    "\n",
    "time_pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('onehot_pipeline', Pipeline([\n",
    "            ('onehot_union', FeatureUnion([\n",
    "                ('hour', DateTimeExtractor('hour')),\n",
    "                ('month', DateTimeExtractor('month')), \n",
    "                ('dayofweek', DateTimeExtractor('dayofweek')), \n",
    "                ('holiday', HolidaySelector())\n",
    "            ])),\n",
    "            ('onehot_encoder', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('float_pipeline', Pipeline([\n",
    "            ('float_union', FeatureUnion([\n",
    "                ('year', DateTimeExtractor('year')),\n",
    "                ('floats', ColumnSelector(['precip_prob', 'temperature', 'humidity', 'wind_speed', 'rides'])),\n",
    "            ])),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]))\n",
    "    ]))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    all_pipeline.fit(X.iloc[0:train_cut, :])\n",
    "    all_X = all_pipeline.transform(X)\n",
    "  \n",
    "    time_pipeline.fit(X.iloc[0:train_cut, :])\n",
    "    time_X = time_pipeline.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_pipeline.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(all_pipeline, 'all_pipeline.pkl', compress=1)\n",
    "joblib.dump(time_pipeline, 'time_pipeline.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(time_X, all_X, start, stop):\n",
    "    ONE_DAY = 24\n",
    "    lookback = 28*ONE_DAY \n",
    "    lag = 2*ONE_DAY \n",
    "    \n",
    "    if start < lookback + lag:\n",
    "        start = lookback + lag\n",
    "\n",
    "    input_time_X = np.zeros((stop-start, lookback//ONE_DAY, len(time_X[0])))\n",
    "    input_all_X = np.zeros((stop-start, len(all_X[0])))\n",
    "    \n",
    "    for i in range(start, stop):\n",
    "        input_time_X[i-start] = time_X[i-lookback-lag:i-lag:ONE_DAY]\n",
    "        input_all_X[i-start] = all_X[i]\n",
    "    \n",
    "    return input_time_X, input_all_X\n",
    "\n",
    "input_time_X, input_all_X = create_datasets(time_X, all_X, 0, train_cut)\n",
    "v_input_time_X, v_input_all_X = create_datasets(time_X, all_X, train_cut, validate_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "temporal (InputLayer)           (None, 28, 51)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "temporal_gru_1 (GRU)            (None, 32)           8064        temporal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "all (InputLayer)                (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "temporal_dense_1 (Dense)        (None, 64)           2112        temporal_gru_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "all_dense_1 (Dense)             (None, 64)           3904        all[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "temporal_dropout_1 (Dropout)    (None, 64)           0           temporal_dense_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "all_dropout_1 (Dropout)         (None, 64)           0           all_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 128)          0           temporal_dropout_1[0][0]         \n",
      "                                                                 all_dropout_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat_dense_1 (Dense)          (None, 128)          16512       concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_dropout_1 (Dropout)      (None, 128)          0           concat_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concat_dense_2 (Dense)          (None, 128)          16512       concat_dropout_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concat_dropout_2 (Dropout)      (None, 128)          0           concat_dense_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            129         concat_dropout_2[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 47,233\n",
      "Trainable params: 47,233\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "temporal = Input(shape=(len(input_time_X[0]), len(input_time_X[0][0])), name='temporal')\n",
    "temporal1 = GRU(32, dropout=0.5, recurrent_dropout=0.5, name='temporal_gru_1')(temporal)\n",
    "temporal1 = Dense(64, name='temporal_dense_1')(temporal1)\n",
    "temporal1 = Dropout(0.5, name='temporal_dropout_1')(temporal1)\n",
    "\n",
    "\n",
    "weather = Input(shape=(len(input_all_X[0]), ), name='all')\n",
    "weather1 = Dense(64, activation='relu', name='all_dense_1')(weather)\n",
    "weather1 = Dropout(0.5, name='all_dropout_1')(weather1)\n",
    "\n",
    "\n",
    "concat = concatenate([temporal1, weather1], name='concat')\n",
    "concat1 = Dense(128, activation='relu', name='concat_dense_1')(concat)\n",
    "concat1 = Dropout(0.5, name='concat_dropout_1')(concat1)\n",
    "concat1 = Dense(128, activation='relu', name='concat_dense_2')(concat1)\n",
    "concat1 = Dropout(0.5, name='concat_dropout_2')(concat1)\n",
    "output = Dense(1, name='output')(concat1)\n",
    "\n",
    "\n",
    "model = Model([temporal, weather], output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32333 samples, validate on 4132 samples\n",
      "Epoch 1/100\n",
      "32333/32333 [==============================] - 20s 613us/step - loss: 819302.7414 - val_loss: 741155.4454\n",
      "Epoch 2/100\n",
      "32333/32333 [==============================] - 17s 524us/step - loss: 368104.1903 - val_loss: 672789.0495\n",
      "Epoch 3/100\n",
      "32333/32333 [==============================] - 17s 523us/step - loss: 297840.3854 - val_loss: 527269.6971\n",
      "Epoch 4/100\n",
      "32333/32333 [==============================] - 17s 526us/step - loss: 255298.4794 - val_loss: 443803.2124\n",
      "Epoch 5/100\n",
      "32333/32333 [==============================] - 17s 527us/step - loss: 233883.0458 - val_loss: 331667.1234\n",
      "Epoch 6/100\n",
      "32333/32333 [==============================] - 17s 524us/step - loss: 217867.2793 - val_loss: 303597.4737\n",
      "Epoch 7/100\n",
      "32333/32333 [==============================] - 17s 528us/step - loss: 208450.4635 - val_loss: 303188.7834\n",
      "Epoch 8/100\n",
      "32333/32333 [==============================] - 17s 524us/step - loss: 203613.1941 - val_loss: 278871.1286\n",
      "Epoch 9/100\n",
      "32333/32333 [==============================] - 17s 525us/step - loss: 195287.7911 - val_loss: 289299.0015\n",
      "Epoch 10/100\n",
      "32333/32333 [==============================] - 17s 526us/step - loss: 191123.4432 - val_loss: 264607.2472\n",
      "Epoch 11/100\n",
      "32333/32333 [==============================] - 17s 533us/step - loss: 193084.0579 - val_loss: 266197.8499\n",
      "Epoch 12/100\n",
      "32333/32333 [==============================] - 17s 522us/step - loss: 187217.0360 - val_loss: 246110.0244\n",
      "Epoch 13/100\n",
      "32333/32333 [==============================] - 17s 527us/step - loss: 183077.5633 - val_loss: 254827.3685\n",
      "Epoch 14/100\n",
      "32333/32333 [==============================] - 17s 530us/step - loss: 182763.7039 - val_loss: 266638.1973\n",
      "Epoch 15/100\n",
      "32333/32333 [==============================] - 17s 528us/step - loss: 185633.4418 - val_loss: 244104.3301\n",
      "Epoch 16/100\n",
      "32333/32333 [==============================] - 17s 526us/step - loss: 180228.3365 - val_loss: 250804.8674\n",
      "Epoch 17/100\n",
      "32333/32333 [==============================] - 17s 532us/step - loss: 180030.3135 - val_loss: 233968.2076\n",
      "Epoch 18/100\n",
      "32333/32333 [==============================] - 17s 531us/step - loss: 178724.0161 - val_loss: 239643.3493\n",
      "Epoch 19/100\n",
      "32333/32333 [==============================] - 17s 526us/step - loss: 173495.8207 - val_loss: 251180.7146\n",
      "Epoch 20/100\n",
      "32333/32333 [==============================] - 17s 528us/step - loss: 179279.4233 - val_loss: 267595.6908\n",
      "Epoch 21/100\n",
      "32333/32333 [==============================] - 17s 525us/step - loss: 176214.2941 - val_loss: 225305.7584\n",
      "Epoch 22/100\n",
      "32333/32333 [==============================] - 17s 527us/step - loss: 176663.5237 - val_loss: 221125.4401\n",
      "Epoch 23/100\n",
      "32333/32333 [==============================] - 17s 529us/step - loss: 177067.9709 - val_loss: 223388.8467\n",
      "Epoch 24/100\n",
      "32333/32333 [==============================] - 17s 526us/step - loss: 173736.0344 - val_loss: 234428.0325\n",
      "Epoch 25/100\n",
      "32333/32333 [==============================] - 17s 531us/step - loss: 171479.1070 - val_loss: 215683.8329\n",
      "Epoch 26/100\n",
      "32333/32333 [==============================] - 17s 528us/step - loss: 176255.9244 - val_loss: 215064.4302\n",
      "Epoch 27/100\n",
      "32333/32333 [==============================] - 21s 638us/step - loss: 172136.4884 - val_loss: 233793.6467\n",
      "Epoch 28/100\n",
      "32333/32333 [==============================] - 21s 636us/step - loss: 169508.1477 - val_loss: 226706.5036\n",
      "Epoch 29/100\n",
      "32333/32333 [==============================] - 18s 570us/step - loss: 168663.9232 - val_loss: 227065.8183\n",
      "Epoch 30/100\n",
      "32333/32333 [==============================] - 19s 579us/step - loss: 170237.0112 - val_loss: 214026.4722\n",
      "Epoch 31/100\n",
      "32333/32333 [==============================] - 19s 583us/step - loss: 170700.9381 - val_loss: 229313.3113\n",
      "Epoch 32/100\n",
      "32333/32333 [==============================] - 19s 596us/step - loss: 167816.8833 - val_loss: 211058.0590\n",
      "Epoch 33/100\n",
      "32333/32333 [==============================] - 19s 591us/step - loss: 165668.6103 - val_loss: 234076.8687\n",
      "Epoch 34/100\n",
      "32333/32333 [==============================] - 21s 661us/step - loss: 165975.0657 - val_loss: 207814.3669\n",
      "Epoch 35/100\n",
      "32333/32333 [==============================] - 20s 616us/step - loss: 167685.7034 - val_loss: 209765.2733\n",
      "Epoch 36/100\n",
      "32333/32333 [==============================] - 20s 607us/step - loss: 164799.1580 - val_loss: 229518.2014\n",
      "Epoch 37/100\n",
      "32333/32333 [==============================] - 19s 581us/step - loss: 166356.0999 - val_loss: 214491.5393\n",
      "Epoch 38/100\n",
      "32333/32333 [==============================] - 20s 607us/step - loss: 169658.8974 - val_loss: 218368.1948\n",
      "Epoch 39/100\n",
      "32333/32333 [==============================] - 20s 612us/step - loss: 164331.2690 - val_loss: 213830.7031\n",
      "Epoch 40/100\n",
      "32333/32333 [==============================] - 19s 585us/step - loss: 165152.4803 - val_loss: 219344.7363\n",
      "Epoch 41/100\n",
      "32333/32333 [==============================] - 19s 575us/step - loss: 164147.9223 - val_loss: 207051.1845\n",
      "Epoch 42/100\n",
      "32333/32333 [==============================] - 19s 587us/step - loss: 166259.7499 - val_loss: 234099.0770\n",
      "Epoch 43/100\n",
      "32333/32333 [==============================] - 19s 581us/step - loss: 161595.5112 - val_loss: 215571.8989\n",
      "Epoch 44/100\n",
      "32333/32333 [==============================] - 18s 570us/step - loss: 164451.9466 - val_loss: 209731.7081\n",
      "Epoch 45/100\n",
      "32333/32333 [==============================] - 18s 570us/step - loss: 161452.0755 - val_loss: 217536.2005\n",
      "Epoch 46/100\n",
      "32333/32333 [==============================] - 18s 567us/step - loss: 165210.3453 - val_loss: 221894.0350\n",
      "Epoch 47/100\n",
      "32333/32333 [==============================] - 19s 575us/step - loss: 164512.3526 - val_loss: 221578.6448\n",
      "Epoch 48/100\n",
      "32333/32333 [==============================] - 17s 539us/step - loss: 163074.0393 - val_loss: 215709.8385\n",
      "Epoch 49/100\n",
      "32333/32333 [==============================] - 18s 559us/step - loss: 161270.4357 - val_loss: 194788.3028\n",
      "Epoch 50/100\n",
      "32333/32333 [==============================] - 18s 553us/step - loss: 162377.7534 - val_loss: 197522.1290\n",
      "Epoch 51/100\n",
      "32333/32333 [==============================] - 17s 536us/step - loss: 161561.5320 - val_loss: 202377.0063\n",
      "Epoch 52/100\n",
      "32333/32333 [==============================] - 18s 552us/step - loss: 162291.9678 - val_loss: 220709.0318\n",
      "Epoch 53/100\n",
      "32333/32333 [==============================] - 21s 646us/step - loss: 155937.9426 - val_loss: 206591.5840\n",
      "Epoch 54/100\n",
      "32333/32333 [==============================] - 19s 590us/step - loss: 157988.0182 - val_loss: 200913.6720\n",
      "Epoch 55/100\n",
      "32333/32333 [==============================] - 20s 615us/step - loss: 156755.6576 - val_loss: 196909.0433\n",
      "Epoch 56/100\n",
      "32333/32333 [==============================] - 20s 609us/step - loss: 158364.7205 - val_loss: 214058.7918\n",
      "Epoch 57/100\n",
      "32333/32333 [==============================] - 21s 639us/step - loss: 156598.2661 - val_loss: 201022.3440\n",
      "Epoch 58/100\n",
      "32333/32333 [==============================] - 19s 602us/step - loss: 151231.0732 - val_loss: 211407.7258\n",
      "Epoch 59/100\n",
      "32333/32333 [==============================] - 20s 609us/step - loss: 157644.2138 - val_loss: 191302.2690\n",
      "Epoch 60/100\n",
      "32333/32333 [==============================] - 19s 602us/step - loss: 155610.9601 - val_loss: 200490.3398\n",
      "Epoch 61/100\n",
      "32333/32333 [==============================] - 20s 604us/step - loss: 154995.5268 - val_loss: 196842.8172\n",
      "Epoch 62/100\n",
      "32333/32333 [==============================] - 20s 625us/step - loss: 154295.5261 - val_loss: 203826.6919\n",
      "Epoch 63/100\n",
      "32333/32333 [==============================] - 19s 596us/step - loss: 154931.7522 - val_loss: 201141.7950\n",
      "Epoch 64/100\n",
      "32333/32333 [==============================] - 19s 583us/step - loss: 154046.8912 - val_loss: 202321.6217\n",
      "Epoch 65/100\n",
      "32333/32333 [==============================] - 18s 563us/step - loss: 150755.2518 - val_loss: 200476.7914\n",
      "Epoch 66/100\n",
      "32333/32333 [==============================] - 18s 558us/step - loss: 151578.4163 - val_loss: 213346.3288\n",
      "Epoch 67/100\n",
      "32333/32333 [==============================] - 20s 608us/step - loss: 149047.0565 - val_loss: 193954.4181\n",
      "Epoch 68/100\n",
      "32333/32333 [==============================] - 19s 585us/step - loss: 153172.1612 - val_loss: 199771.3819\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32333/32333 [==============================] - 19s 590us/step - loss: 150766.3307 - val_loss: 196857.4604\n",
      "Epoch 70/100\n",
      "32333/32333 [==============================] - 19s 584us/step - loss: 147194.5679 - val_loss: 193133.2690\n",
      "Epoch 71/100\n",
      "32333/32333 [==============================] - 19s 583us/step - loss: 144708.7711 - val_loss: 193111.2823\n",
      "Epoch 72/100\n",
      "32333/32333 [==============================] - 19s 587us/step - loss: 145702.7963 - val_loss: 197001.6493\n",
      "Epoch 73/100\n",
      "32333/32333 [==============================] - 19s 585us/step - loss: 146357.7212 - val_loss: 190549.7509\n",
      "Epoch 74/100\n",
      "32333/32333 [==============================] - 19s 586us/step - loss: 144147.7585 - val_loss: 190285.2359\n",
      "Epoch 75/100\n",
      "32333/32333 [==============================] - 19s 596us/step - loss: 144693.6224 - val_loss: 190099.2057\n",
      "Epoch 76/100\n",
      "32333/32333 [==============================] - 19s 584us/step - loss: 146070.0904 - val_loss: 190835.5111\n",
      "Epoch 77/100\n",
      "32333/32333 [==============================] - 19s 591us/step - loss: 145663.0246 - val_loss: 192842.5485\n",
      "Epoch 78/100\n",
      "32333/32333 [==============================] - 19s 594us/step - loss: 146464.9753 - val_loss: 189461.7338\n",
      "Epoch 79/100\n",
      "32333/32333 [==============================] - 19s 590us/step - loss: 143370.4183 - val_loss: 192680.7495\n",
      "Epoch 80/100\n",
      "32333/32333 [==============================] - 19s 593us/step - loss: 141967.9804 - val_loss: 192008.4676\n",
      "Epoch 81/100\n",
      "32333/32333 [==============================] - 19s 586us/step - loss: 144209.0762 - val_loss: 190103.0459\n",
      "Epoch 82/100\n",
      "32333/32333 [==============================] - 19s 582us/step - loss: 143519.3732 - val_loss: 191752.0523\n",
      "Epoch 83/100\n",
      "32333/32333 [==============================] - 19s 593us/step - loss: 143860.3833 - val_loss: 189329.1879\n",
      "Epoch 84/100\n",
      "32333/32333 [==============================] - 19s 596us/step - loss: 143057.5440 - val_loss: 189390.3029\n",
      "Epoch 85/100\n",
      "32333/32333 [==============================] - 19s 595us/step - loss: 141056.4059 - val_loss: 188623.0259\n",
      "Epoch 86/100\n",
      "32333/32333 [==============================] - 19s 594us/step - loss: 142703.4250 - val_loss: 192289.3367\n",
      "Epoch 87/100\n",
      "32333/32333 [==============================] - 19s 585us/step - loss: 141203.2801 - val_loss: 190843.8360\n",
      "Epoch 88/100\n",
      "32333/32333 [==============================] - 19s 583us/step - loss: 140772.7633 - val_loss: 189713.2986\n",
      "Epoch 89/100\n",
      "32333/32333 [==============================] - 19s 591us/step - loss: 140326.0577 - val_loss: 190003.5770\n",
      "Epoch 90/100\n",
      "32333/32333 [==============================] - 19s 601us/step - loss: 144133.7825 - val_loss: 191121.5297\n",
      "Epoch 91/100\n",
      "32333/32333 [==============================] - 19s 600us/step - loss: 144007.1562 - val_loss: 190236.6023\n",
      "Epoch 92/100\n",
      "32333/32333 [==============================] - 19s 594us/step - loss: 144472.3268 - val_loss: 192203.7250\n",
      "Epoch 93/100\n",
      "32333/32333 [==============================] - 19s 591us/step - loss: 143139.5679 - val_loss: 191820.7628\n",
      "Epoch 94/100\n",
      "32333/32333 [==============================] - 19s 588us/step - loss: 143501.1223 - val_loss: 189288.0400\n",
      "Epoch 95/100\n",
      "32333/32333 [==============================] - 19s 589us/step - loss: 139729.8551 - val_loss: 190364.2264\n",
      "Epoch 96/100\n",
      "32333/32333 [==============================] - 19s 588us/step - loss: 143010.0852 - val_loss: 190776.7591\n",
      "Epoch 97/100\n",
      "32333/32333 [==============================] - 19s 591us/step - loss: 140431.4344 - val_loss: 191254.5065\n",
      "Epoch 98/100\n",
      "32333/32333 [==============================] - 19s 591us/step - loss: 142334.0434 - val_loss: 190865.3689\n",
      "Epoch 99/100\n",
      "32333/32333 [==============================] - 19s 594us/step - loss: 139937.0960 - val_loss: 190471.9745\n",
      "Epoch 100/100\n",
      "32333/32333 [==============================] - 19s 592us/step - loss: 141042.1410 - val_loss: 190542.7886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c004184390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=10\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='new_model_5.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit([input_time_X, input_all_X], y[30*24:train_cut].to_numpy(), epochs=100, batch_size=64,\n",
    "                validation_data=([v_input_time_X, v_input_all_X], y[train_cut:validate_cut]),\n",
    "                callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32333/32333 [==============================] - 16s 498us/step\n",
      "51777.24979298675\n",
      "4132/4132 [==============================] - 2s 465us/step\n",
      "188623.02609964908\n"
     ]
    }
   ],
   "source": [
    "model = load_model('new_model_5.h5')\n",
    "\n",
    "print(model.evaluate([input_time_X, input_all_X],  y[30*24:train_cut].to_numpy()))\n",
    "print(model.evaluate([v_input_time_X, v_input_all_X], y[train_cut:validate_cut].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
