{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, MinMaxScaler\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Dense, Dropout, concatenate, Input\n",
    "from keras.optimizers import RMSprop\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./historic_data.csv')\n",
    "data['actual'] = data['rides']\n",
    "train_cut = int(len(data) * 0.8)\n",
    "validate_cut = int(len(data) * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>icon</th>\n",
       "      <th>precip_prob</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>77.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.06</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>75.62</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.93</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.31</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.32</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.16</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>72.42</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour  month  day_of_week  sunrise   icon  precip_prob  \\\n",
       "0  2013-06-01     0      6            7        0  clear         0.01   \n",
       "1  2013-06-01     1      6            7        0  clear         0.01   \n",
       "2  2013-06-01     2      6            7        0  clear         0.01   \n",
       "3  2013-06-01     3      6            7        0  clear         0.01   \n",
       "4  2013-06-01     4      6            7        0  clear         0.01   \n",
       "\n",
       "   temperature  humidity  wind_speed  actual  \n",
       "0        77.65      0.61        2.06     152  \n",
       "1        75.62      0.67        1.93     102  \n",
       "2        74.72      0.70        2.31      67  \n",
       "3        73.32      0.76        2.16      41  \n",
       "4        72.42      0.79        1.93      16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data.iloc[:, data.columns != 'rides'], data.iloc[:, data.columns == 'rides'].iloc[:, 0]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.applymap(lambda x: float(pd.to_datetime(x).year))\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.columns]\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.func(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_selector', ColumnSelector(['hour', 'day_of_week', 'month'])),\n",
    "            ('cat_encoder', OneHotEncoder(sparse=False))\n",
    "        ])),\n",
    "        ('year', Pipeline([\n",
    "            ('year_selector', ColumnSelector(['date'])),\n",
    "            ('year_extractor', YearExtractor()),\n",
    "        ])),\n",
    "        ('int', Pipeline([\n",
    "            ('int_selector', ColumnSelector(['sunrise', 'precip_prob', 'temperature', 'humidity', 'wind_speed', 'actual'])),\n",
    "        ])),\n",
    "    ])),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X.iloc[0:train_cut, :])\n",
    "ft_X = pipeline.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dl_X_pipeline.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(pipeline, 'dl_X_pipeline.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\Anaconda3\\envs\\citibike-dashboard\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array(y[0:train_cut]).reshape(-1, 1))\n",
    "\n",
    "min_max_y = scaler.transform(np.array(y).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dl_y_pipeline.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'dl_y_pipeline.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(predictors, response, start, stop, lookback, lag, batch_size=2):\n",
    "    index = start\n",
    "    while True:\n",
    "        if index + batch_size > stop:\n",
    "            samples = np.zeros((stop-index, lookback, 1))\n",
    "            meta = np.zeros((stop-index, len(predictors[0])-1))\n",
    "            targets = np.zeros(stop-index)\n",
    "        else:\n",
    "            samples = np.zeros((batch_size, lookback, 1))\n",
    "            meta = np.zeros((batch_size, len(predictors[0])-1))\n",
    "            targets = np.zeros(batch_size)\n",
    "        for i in range(samples.shape[0]):\n",
    "            samples[i] = predictors[index-lookback-lag+i:index-lag+i, -1].reshape(-1, 1)\n",
    "            meta[i] = predictors[index + i, :-1]\n",
    "            targets[i] = response[index + i]\n",
    "\n",
    "        index += batch_size\n",
    "        if index >= stop:\n",
    "            index = start\n",
    "        \n",
    "        yield [samples, meta], targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=10\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='my_model6.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "        \n",
    "lookback = 7*24 # seven days\n",
    "lag = 1*24 # one day\n",
    "batch_size = 64\n",
    "train_steps = (train_cut - lookback - lag) // batch_size + 1\n",
    "val_steps = (validate_cut - train_cut) // batch_size + 1\n",
    "\n",
    "\n",
    "train_gen = generator(ft_X, min_max_y, lookback+lag, train_cut, lookback, lag, batch_size)\n",
    "validate_gen = generator(ft_X, min_max_y, train_cut, validate_cut, lookback, lag, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "historical (InputLayer)         (None, 168, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 64)           12672       historical[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weather (InputLayer)            (None, 49)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           3200        weather[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            65          dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,865\n",
      "Trainable params: 44,865\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "historical = Input(shape=(lookback, 1), name='historical')\n",
    "historical1 = GRU(64, input_shape=(None, ))(historical)\n",
    "historical1 = Dense(64, activation='relu')(historical1)\n",
    "historical1 = Dropout(0.5)(historical1)\n",
    "\n",
    "weather = Input(shape=(49, ), name='weather')\n",
    "weather1 = Dense(64, activation='relu')(weather)\n",
    "weather1 = Dropout(0.5)(weather1)\n",
    "\n",
    "concat = concatenate([historical1, weather1])\n",
    "concat1 = Dense(128, activation='relu')(concat)\n",
    "concat1 = Dropout(0.5)(concat1)\n",
    "concat1 = Dense(64, activation='relu')(concat1)\n",
    "concat1 = Dropout(0.5)(concat1)\n",
    "output = Dense(1)(concat1)\n",
    "\n",
    "model = Model([historical, weather], output)\n",
    "model.compile(optimizer=RMSprop(), loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "495/495 [==============================] - 130s 262ms/step - loss: 0.0137 - mean_absolute_error: 0.0825 - val_loss: 0.0284 - val_mean_absolute_error: 0.1200\n",
      "Epoch 2/75\n",
      "495/495 [==============================] - 86s 173ms/step - loss: 0.0062 - mean_absolute_error: 0.0560 - val_loss: 0.0203 - val_mean_absolute_error: 0.0986\n",
      "Epoch 3/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0049 - mean_absolute_error: 0.0498 - val_loss: 0.0165 - val_mean_absolute_error: 0.0899\n",
      "Epoch 4/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0043 - mean_absolute_error: 0.0459 - val_loss: 0.0133 - val_mean_absolute_error: 0.0797\n",
      "Epoch 5/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0039 - mean_absolute_error: 0.0436 - val_loss: 0.0138 - val_mean_absolute_error: 0.0794\n",
      "Epoch 6/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0036 - mean_absolute_error: 0.0418 - val_loss: 0.0115 - val_mean_absolute_error: 0.0753\n",
      "Epoch 7/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0034 - mean_absolute_error: 0.0405 - val_loss: 0.0104 - val_mean_absolute_error: 0.0717\n",
      "Epoch 8/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0033 - mean_absolute_error: 0.0398 - val_loss: 0.0090 - val_mean_absolute_error: 0.0682\n",
      "Epoch 9/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0033 - mean_absolute_error: 0.0395 - val_loss: 0.0091 - val_mean_absolute_error: 0.0669\n",
      "Epoch 10/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0031 - mean_absolute_error: 0.0387 - val_loss: 0.0107 - val_mean_absolute_error: 0.0716\n",
      "Epoch 11/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0030 - mean_absolute_error: 0.0385 - val_loss: 0.0090 - val_mean_absolute_error: 0.0677\n",
      "Epoch 12/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0030 - mean_absolute_error: 0.0378 - val_loss: 0.0077 - val_mean_absolute_error: 0.0643\n",
      "Epoch 13/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0030 - mean_absolute_error: 0.0374 - val_loss: 0.0084 - val_mean_absolute_error: 0.0644\n",
      "Epoch 14/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0030 - mean_absolute_error: 0.0372 - val_loss: 0.0082 - val_mean_absolute_error: 0.0652\n",
      "Epoch 15/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0029 - mean_absolute_error: 0.0370 - val_loss: 0.0075 - val_mean_absolute_error: 0.0623\n",
      "Epoch 16/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0029 - mean_absolute_error: 0.0369 - val_loss: 0.0092 - val_mean_absolute_error: 0.0672\n",
      "Epoch 17/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0029 - mean_absolute_error: 0.0367 - val_loss: 0.0074 - val_mean_absolute_error: 0.0621\n",
      "Epoch 18/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0028 - mean_absolute_error: 0.0364 - val_loss: 0.0070 - val_mean_absolute_error: 0.0597\n",
      "Epoch 19/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0029 - mean_absolute_error: 0.0365 - val_loss: 0.0084 - val_mean_absolute_error: 0.0667\n",
      "Epoch 20/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0028 - mean_absolute_error: 0.0363 - val_loss: 0.0079 - val_mean_absolute_error: 0.0632\n",
      "Epoch 21/75\n",
      "495/495 [==============================] - 86s 174ms/step - loss: 0.0028 - mean_absolute_error: 0.0362 - val_loss: 0.0072 - val_mean_absolute_error: 0.0606\n",
      "Epoch 22/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0028 - mean_absolute_error: 0.0359 - val_loss: 0.0085 - val_mean_absolute_error: 0.0659\n",
      "Epoch 23/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0027 - mean_absolute_error: 0.0358 - val_loss: 0.0082 - val_mean_absolute_error: 0.0642\n",
      "Epoch 24/75\n",
      "495/495 [==============================] - 84s 170ms/step - loss: 0.0028 - mean_absolute_error: 0.0360 - val_loss: 0.0088 - val_mean_absolute_error: 0.0665\n",
      "Epoch 25/75\n",
      "495/495 [==============================] - 84s 170ms/step - loss: 0.0028 - mean_absolute_error: 0.0358 - val_loss: 0.0086 - val_mean_absolute_error: 0.0661\n",
      "Epoch 26/75\n",
      "495/495 [==============================] - 84s 170ms/step - loss: 0.0027 - mean_absolute_error: 0.0355 - val_loss: 0.0080 - val_mean_absolute_error: 0.0627\n",
      "Epoch 27/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0027 - mean_absolute_error: 0.0357 - val_loss: 0.0081 - val_mean_absolute_error: 0.0651\n",
      "Epoch 28/75\n",
      "495/495 [==============================] - 84s 170ms/step - loss: 0.0027 - mean_absolute_error: 0.0356 - val_loss: 0.0078 - val_mean_absolute_error: 0.0616\n",
      "Epoch 29/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0035 - mean_absolute_error: 0.0401 - val_loss: 0.0043 - val_mean_absolute_error: 0.0473\n",
      "Epoch 30/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0036 - mean_absolute_error: 0.0401 - val_loss: 0.0040 - val_mean_absolute_error: 0.0460\n",
      "Epoch 31/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0036 - mean_absolute_error: 0.0396 - val_loss: 0.0041 - val_mean_absolute_error: 0.0466\n",
      "Epoch 32/75\n",
      "495/495 [==============================] - 84s 170ms/step - loss: 0.0034 - mean_absolute_error: 0.0389 - val_loss: 0.0039 - val_mean_absolute_error: 0.0456\n",
      "Epoch 33/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0033 - mean_absolute_error: 0.0385 - val_loss: 0.0038 - val_mean_absolute_error: 0.0458\n",
      "Epoch 34/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0033 - mean_absolute_error: 0.0382 - val_loss: 0.0037 - val_mean_absolute_error: 0.0449\n",
      "Epoch 35/75\n",
      "495/495 [==============================] - 84s 171ms/step - loss: 0.0033 - mean_absolute_error: 0.0381 - val_loss: 0.0036 - val_mean_absolute_error: 0.0444\n",
      "Epoch 36/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0033 - mean_absolute_error: 0.0382 - val_loss: 0.0036 - val_mean_absolute_error: 0.0446\n",
      "Epoch 37/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0032 - mean_absolute_error: 0.0376 - val_loss: 0.0036 - val_mean_absolute_error: 0.0444\n",
      "Epoch 38/75\n",
      "495/495 [==============================] - 85s 172ms/step - loss: 0.0033 - mean_absolute_error: 0.0378 - val_loss: 0.0036 - val_mean_absolute_error: 0.0437\n",
      "Epoch 39/75\n",
      "495/495 [==============================] - 84s 170ms/step - loss: 0.0032 - mean_absolute_error: 0.0378 - val_loss: 0.0035 - val_mean_absolute_error: 0.0438\n",
      "Epoch 40/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0031 - mean_absolute_error: 0.0373 - val_loss: 0.0036 - val_mean_absolute_error: 0.0445\n",
      "Epoch 41/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0032 - mean_absolute_error: 0.0375 - val_loss: 0.0035 - val_mean_absolute_error: 0.0442\n",
      "Epoch 42/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0032 - mean_absolute_error: 0.0374 - val_loss: 0.0036 - val_mean_absolute_error: 0.0439\n",
      "Epoch 43/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0031 - mean_absolute_error: 0.0372 - val_loss: 0.0036 - val_mean_absolute_error: 0.0444\n",
      "Epoch 44/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0030 - mean_absolute_error: 0.0368 - val_loss: 0.0036 - val_mean_absolute_error: 0.0441\n",
      "Epoch 45/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0032 - mean_absolute_error: 0.0373 - val_loss: 0.0036 - val_mean_absolute_error: 0.0444\n",
      "Epoch 46/75\n",
      "495/495 [==============================] - 84s 170ms/step - loss: 0.0030 - mean_absolute_error: 0.0368 - val_loss: 0.0037 - val_mean_absolute_error: 0.0449\n",
      "Epoch 47/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0030 - mean_absolute_error: 0.0368 - val_loss: 0.0036 - val_mean_absolute_error: 0.0446\n",
      "Epoch 48/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0030 - mean_absolute_error: 0.0367 - val_loss: 0.0036 - val_mean_absolute_error: 0.0443\n",
      "Epoch 49/75\n",
      "495/495 [==============================] - 86s 175ms/step - loss: 0.0031 - mean_absolute_error: 0.0368 - val_loss: 0.0036 - val_mean_absolute_error: 0.0441\n",
      "Epoch 50/75\n",
      "495/495 [==============================] - 85s 171ms/step - loss: 0.0055 - mean_absolute_error: 0.0495 - val_loss: 0.0063 - val_mean_absolute_error: 0.0593\n",
      "Epoch 51/75\n",
      "495/495 [==============================] - 86s 173ms/step - loss: 0.0044 - mean_absolute_error: 0.0444 - val_loss: 0.0077 - val_mean_absolute_error: 0.0653\n",
      "Epoch 52/75\n",
      "495/495 [==============================] - 85s 172ms/step - loss: 0.0041 - mean_absolute_error: 0.0432 - val_loss: 0.0077 - val_mean_absolute_error: 0.0652\n",
      "Epoch 53/75\n",
      "495/495 [==============================] - 85s 172ms/step - loss: 0.0041 - mean_absolute_error: 0.0432 - val_loss: 0.0077 - val_mean_absolute_error: 0.0654\n",
      "Epoch 54/75\n",
      "495/495 [==============================] - 86s 173ms/step - loss: 0.0040 - mean_absolute_error: 0.0430 - val_loss: 0.0076 - val_mean_absolute_error: 0.0648\n",
      "Epoch 55/75\n",
      "495/495 [==============================] - 88s 178ms/step - loss: 0.0041 - mean_absolute_error: 0.0429 - val_loss: 0.0075 - val_mean_absolute_error: 0.0641\n",
      "Epoch 56/75\n",
      "495/495 [==============================] - 86s 175ms/step - loss: 0.0040 - mean_absolute_error: 0.0424 - val_loss: 0.0072 - val_mean_absolute_error: 0.0631\n",
      "Epoch 57/75\n",
      "495/495 [==============================] - 93s 188ms/step - loss: 0.0039 - mean_absolute_error: 0.0422 - val_loss: 0.0069 - val_mean_absolute_error: 0.0616\n",
      "Epoch 58/75\n",
      "495/495 [==============================] - 94s 190ms/step - loss: 0.0040 - mean_absolute_error: 0.0422 - val_loss: 0.0071 - val_mean_absolute_error: 0.0622\n",
      "Epoch 59/75\n",
      "495/495 [==============================] - 87s 176ms/step - loss: 0.0038 - mean_absolute_error: 0.0415 - val_loss: 0.0068 - val_mean_absolute_error: 0.0612\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=75, \n",
    "                    validation_data=validate_gen, validation_steps=val_steps,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210985.83112290205"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model.load_weights('my_model6.h5')\n",
    "model.compile(optimizer=RMSprop(), loss='mse', metrics=['mae'])\n",
    "\n",
    "new_gen = generator(ft_X, min_max_y, train_cut, validate_cut, lookback, lag, batch_size)\n",
    "predictions = model.predict_generator(new_gen, steps=val_steps)\n",
    "mean_squared_error(scaler.inverse_transform(predictions), y[train_cut:validate_cut])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
